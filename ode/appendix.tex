\chapter{Appendix}

% \section{To the proof of the theorem of Peano}

% \begin{definition}
%   A function sequence $f^n$ is called \textbf{equicontinuous}, if it holds:
%   \begin{gather*}
%   \forall \,\epsilon > 0
%   \;\exists \, \delta > 0
%   \;\forall \, n \in \mathbb{N}
%   \;\forall |y-x| < \delta 
%   \quad:\quad |f^n(y)-f^n(x)| < \epsilon    
%   \end{gather*}
% \end{definition}

% \begin{theorem}[Arzela-Ascoli]\label{theorem:arzelaascoli}
%   Let be $f^h$ a equicontinuous, uniformly bounded sequence
%   of functions. Then it exists a subsequence $f^{h_i}$ which converges to a 
% 	uniformly continuous function $f$.
% \end{theorem}

% \begin{todo}
% \begin{proof}
%   Nachzulesen in ...? %%%%%%%%%%%%%%%%
% \end{proof}
% \end{todo}

% \begin{proof}[Proof of the theorem of Peano]
%   I) Choose a sequence $h \to 0$ and compute approximations $u^h(t)$ with  
% 		Euler's method.

%     The method is well-defined, 
% 		if $(t_n,u_n^h) \in D \ \ \ \forall n$ with $|t_n-t_0| \le T$

%     $|u_1^h - u_0| = |h f(t_0,u_0)| \le h M$

%     $|u_n^h - u_0| = | \sum\limits_{k=0}^{n-1} h f(t_k,u_k^h) | 
% 		\le M \underbrace{h n}_{= T} \le M T \le \beta$

%   \noindent II) To show: $u^h(t)$ is uniformly bounded and 
% 		equicontinuous.

%     a) Since $u^h(t) \in D \Rightarrow |u^h(t)-u_0| \le \beta$

%     b) For $\tau,t \in [t_{n-1},t_n]$ holds $|u^h(\tau)-u^h(t)| \le M |\tau-t|$

%     \noindent $\Rightarrow$ The functions $u^h$ are equicontinuous and 
% 		Lipschitz continuous with L-constant $M$.

%     \noindent $\underset{Theorem~\ref{Theorem:arzelaascoli} }{\Rightarrow}$ It exists
% 		a sequence $u_i^h$ with $u_i^h \to u$ and $u$ is equicontinuous.

%   \noindent III) The limit function $u$ solves Volterra's integral equation

%     $u(t) = u_0 + \int\limits_{t_0}^t f(s,u(s))\ \mathrm{d}s$.

%     \noindent To that: (The subsequence index will be omitted in the following)

%     $u^h(t) = u_0 + \sum\limits_{j=0}^k h f(t_j,u_j^h) + (t-t_k) f(t_k,u_k^h)$,

%     \noindent where $t_k$ is the highest point of Euler's method with $t_k < t$.

%     $\begin{array}{lcl}
%       u^h(t) = u_0 + \int\limits_{t_0}^t \Phi^h(s) \ \mathrm{d}s
%         & \text{ with } & \Phi^h(t) = f(t_j,u_j^h) \text{ for } t \in [t_j,t_{j+1}]\\
%       \Big\downarrow h \to 0 & \ & \Big\downarrow h \to 0 \\
%       u(t) = u_0 + \int\limits_{t_0}^t \Phi(s) \ \mathrm{d}s
%         & \text{ with } & \Phi(t) = f(t,u(t))\\
%     \end{array}$

%     \noindent Remains to show: $\Phi^h \to \Phi$ uniformly

% 		This follows from the uniformly continuity of $f$ in $\overline{D}$ and 
% 		the equicontinuity of $u^h \to u$.
% \end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Properties of matrices}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The matrix exponential}
\label{sec:matrix-exponentials}

\begin{definition}
  The matrix exponential $e^A$ of a matrix $A\in \R^{d\times d}$ is defined
  by its power series
  \begin{gather}
    \label{eq:appendix:1}
    e^A = \sum_{k=0}^\infty \frac{A^k}{k!}.
  \end{gather}
\end{definition}

\begin{lemma}
  \label{lemma:appendix:exp-0}
  The power series~\eqref{eq:appendix:1} converges for each matrix $A$.
\end{lemma}
\begin{proof}
  
\end{proof}

\begin{lemma}[Properties of the matrix exponential function] 
  \label{Lemma:appendix:exp-1}
	The following relations hold true:
  \begin{xalignat}2
    \label{eq:appendix:2}
    e^0 &= \identity \\
    \label{eq:appendix:3}
    e^{\alpha A} e^{\beta A} &= e^{(\alpha+\beta) A}, &\forall
    A\in\R^{d\times d}\; \forall \alpha,\beta\in \R,\\
    \label{eq:appendix:4}
    e^A e^{-A} &= \identity &\forall A\in\R^{d\times d}.
  \end{xalignat}
  Moreover, $e^A$ is invertible for arbitrary quadratic matrices $A$.
\end{lemma}

\section{The Banach fixed-point theorem}

\begin{Theorem}{Banach fixed-point theorem}
	Let $\Omega \subset \R$ be a closed set and $f \colon \Omega \to \Omega$
	a contraction, i.e. there holds $|f(x) - f(y)| \le \gamma |x-y|$ for a
	$\gamma \in (0,1)$.

	Then there exists a unique $x^* \in \Omega$ such that $f(x^*) =x^*$.
\end{Theorem}

\begin{proof}
	Let $x_0 \in \Omega$ and define $f(x_k) = x_{k+1}$. First, we prove
	existence unsing the cauchy-criterion. Let $k, n \in \N_0$ and consider
	\begin{gather*}
	|x_k - x_{k+m} | = |f(x_{k-1}) - f(x_{k+m-1})| \le \gamma |x_{k-1} - x_{k+m-1})|.
	\end{gather*}

	Iteratively, we get
	\begin{gather*}
	|x_k - x_{k+m} | \le \gamma^k |x_0 - x_m|.
	\end{gather*}

	We now write $x_0 - x_m = x_0 - x_1 + x_1 - x_2 + \dots + x_{m-1} - x_m$.
	The triangle-inequality yields the estimate
	\begin{gather*}
	\gamma^k |x_0 - x_m| \le \gamma^k |x_0 - x_1| + |x_1 - x_2| + \dots + |x_{m-1} - x_m|  \\
	\le \gamma^k |x_0 - x_1| (1 + \gamma + \gamma ^2 + \dots + \gamma^m) \\
	\le \frac{\gamma^k}{1-\gamma} |x_0 - x_1|.
	\end{gather*}
	As $k$ gets larger the estimate goes to zero.

	Concerning uniqueness, let $x^*$ and $y^*$ be fixpoints.
	\begin{gather*}
	|x^* - y^*| = |f(x*) - f(y^*) | \le \gamma |x^* - y^*|
	\end{gather*}
	Since $\gamma \in (0,1)$ we immediately obtain $|x^* - y^*| = 0$. Using
	that $|a| = 0$ if and only if $a=0$ yields $y^* = x^*$. This concludes the proof.
\end{proof}

\section{The implicit and explicit Euler-method}

	The explicit resp. implicit Euler is given by the one-step method
	\begin{align*}
	&& y_1 = y_0 + h f(y_0) && \text{resp.} && y_1 = y_0 + h f(y_1) &&
	\end{align*}
	Clearly, the explicit Euler is rather easy to compute since all one
	needs are $f$, $h$ and $y_0$. On the other hand, the implicit Euler
	is more difficult since for calculating $y_1$ we need the value of $f$ at $y_1$.

	Consider the following visualizations.
	\begin{center}
	\begin{minipage}[t]{0.42\textwidth}
	\begin{tikzpicture}[domain=0:4]
	\draw[->] (0,0) -- (4.5,0) node[anchor=north] {$t$};
	\draw[->] (0,0) -- (0,4) node[anchor=east] {$y$};
	\draw[dashed] (2,4) -- (2,-0.22) node[anchor=north] {$t_1$};
	\draw  plot[id=exp] function{exp(0.35*x)} node[left] {$u$};
	\draw[-{>[scale=2.0]}] plot[id=exp] function{0.35*x+1} node[right] {$u'(t_0)$};
	\end{tikzpicture}

	For the explicit Euler we take $u_0$ and $u'_0$. $y_1$, our approximated
	solution for $u_1$, is chosen as the intersection point of $t_1$ and
	$g(t) = y_0 + t \cdot u'(t_0)$.
	\end{minipage}
	\begin{minipage}[t]{0.1\textwidth}
	\textcolor{white}{lalalala}
	\end{minipage}
	\begin{minipage}[t]{0.42\textwidth}
	\begin{tikzpicture}[domain=0:4]
	\draw[->] (0,0) -- (4.5,0) node[anchor=north] {$t$};
	\draw[->] (0,0) -- (0,4) node[anchor=east] {$y$};
	\draw[dashed] (2,4) -- (2,-0.22) node[anchor=north] {$t_1$};
	\draw  plot[id=exp] function{exp(0.35*x)} node[left] {$u$};
	\draw[{<[scale=3.0]}-] plot[id=exp] function{0.35*exp(.7)*x+1} node[right] {$u'(t_1)$};
	\end{tikzpicture}

	For implicit Euler we go backwards. On the $t_1$-axis we are looking
	for an the affine function $g$ that fulfills $g(0) = u_0$ and $g'(t_1) = f(t_1)$.
	Then we set $y_1 = g(t_1)$.
	\end{minipage}
	\end{center}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "notes"
%%% End: 
