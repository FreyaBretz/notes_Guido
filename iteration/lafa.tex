
\begin{intro}
  Linear algebra deals with abstract vector spaces, but most results
  on linear mappings are restricted to finite dimensional spaces,
  since they exploit the fact that we can choose a basis of finite
  length. After such a choice, every linear mapping is well-defined by
  assigning its values on the finite set of basis vectors. Thus,
  vector spaces and linear mappings, while typically sets with
  infinitely many elements, can be characterized completely by finite
  sets. The resulting theory yields very strong results by simple means.

  The choice of a basis becomes a more involved endeavor if we allow
  for spaces that do not have a finite basis. We can actually go by
  two very different routes. The route of Hamel bases, which are bases
  of inifintely many vectors, but in order to represent a vector in
  such a basis, we only allow for finite linear combinations.
  
  The other route defines a Schauder basis as a set of vectors, such
  that every vector in the space is the linear combination of
  infinitely many basis vectors. In order to define such a linear
  combination, we have to define the meaning of such an infinite sum,
  namely the convergence of the sum. In the course of such a
  definition, we will learn about a natural extension of
  Euclidean\footnote{We will not distinguish between
    Euclidean real spaces and unitary complex spaces.}
  spaces, namely pre-Hilbert and Hilbert spaces.

  Hilbert spaces share with $\R^n$ the concept of orthogonality. Thus,
  they allow us to define orthogonal bases. Furthermore, they admit
  simple generalizations of the theorem, that for any matrix $A$ with
  $n$ columns there exists an orthogonal decomposition
  \begin{gather}
    \R^n = \ker A \oplus \range{A^T}.
  \end{gather}
\end{intro}

\section{Banach and Hilbert spaces}

\begin{Notation}{field-k}
  This section deals with real and complex vector spaces. Therefore,
  if nothing else is noted, the field $\mathbb K$ may be $\R$ or $\C$.
\end{Notation}

\begin{Definition}{functional}
  Let $V$ be a vector space. A \define{functional} on $V$ is a mapping
  $\phi\colon V\to \mathbb K$. A functional is called \define{linear}, if
  there holds
  \begin{gather}
    \phi(\alpha v+w) = \alpha \phi(v)+\phi(w),
    \qquad\forall \alpha\in \mathbb K, \;v,w\in V.
  \end{gather}
  A functional $\phi\colon V\to \R^+_0$ is called \define{sublinear}, if
  \begin{gather}
    \begin{aligned}
      \phi(\alpha v) &= \abs{\alpha}\phi(v)
      & \forall\alpha&\in\mathbb K,\;v\in V,\\
      \phi(v+w) &\le \phi(v)+\phi(w)
      & \forall v,w&\in V.
    \end{aligned}
  \end{gather}
  A functional $\phi\colon V\to \R^+_0$ is called \define{definite}, if
  \begin{gather}
    \phi(v)=0 \quad \Rightarrow v=0 \qquad\forall v\in V.
  \end{gather}
  A \define{norm} on $V$ is a definite, sublinear functional on $V$.
\end{Definition}

\begin{Definition}{inner-product}
  Let $V$ be a vector space over $\mathbb K$ with $\mathbb K = \mathbb
  C$ or $\mathbb K = \R$. An \define{inner product} on $V$ is a mapping
  $\scal(.,.): V\times V \to \mathbb K$ with the properties
  \begin{xalignat}2
    \scal(\alpha x+y,z) &= \alpha \scal(x,z) + \scal(y,z)
    && \forall x,y,z \in V; \alpha \in \mathbb K\\
    \scal(x,y) &= \overline{\scal(y,x)} && \forall x,y \in V \\
    \scal(x,x) & \ge 0 \quad\forall x\in V &\text{and}
    & \scal(x,x)=0 \Leftrightarrow x=0,
  \end{xalignat}
  usually referred to as (bi-)linearity, symmetry, and
  definiteness. We note that linearity in the second argument follows
  immediately by symmetry.
\end{Definition}

\begin{Lemma}{bcs-inequality}
  For every inner product there holds the
  \define{Bunyakovsky-Cauchy-Schwarz inequality}
  \begin{gather}
    \scal(v,w) \le \sqrt{\scal(v,v)} \sqrt{\scal(w,w)}.
  \end{gather}
\end{Lemma}

\begin{Lemma}{inner-product-norm}
  Every inner product defines a norm by
  \begin{gather}
    \norm{v} = \sqrt{\scal(v,v)}.
  \end{gather}
\end{Lemma}

\begin{Definition}{complete}
  A space $V$ with is \define{complete} with respect to a norm, if all
  \putindex{Cauchy sequence}s with elements in $V$ have their limit in
  $V$. A subspace $W\subset V$ is \define{closed} if it is complete.

  The \define{completion} of a space $V$ with respect to a norm
  consists of the space $V$ and the limits of all Cauchy sequences in
  $V$.
  
  We denote the completion of a space $V$ by
  \begin{gather}
    \overline{V} = \overline{V}^{\norm{\cdot}_V}.
  \end{gather}
\end{Definition}

\begin{remark}
  The definition of completeness in \blockref{Definition}{complete} is
  intuitive, but mathematically vague, since the limit of a Cauchy
  sequence is defined by the completion process itself. The way out is
  the definition of the limit of a Cauchy sequence as an equivalence
  class of the sequences themselves. We call two Cauchy sequences
  $\{v_n\}$ and $\{w_n\}$ equivalent, if
  \begin{gather*}
    \norm{v_n-w_n} \to 0
    \quad\text{as}\quad
    n\to \infty.
  \end{gather*}
  If the limits of both sequences exist, we know that this condition
  is equivalent to both limits being equal. If they don't, they are
  defined by these equivalence classes in a way consistent with the
  standard notion of limits .
\end{remark}

\begin{Definition}{Banach-space}
  A \define{normed vector space} is a vector space $V$ with a norm
  $\norm\cdot$. We may also write $\norm{\cdot}_V$ to highlight the
  connection.

  A vector space $V$ which is complete with respect to its norm is
  called a \define{Banach space}.
\end{Definition}

\begin{Definition}{hilbert-space}  
  A vector space $V$ equipped with an inner product $\scal(.,.)$ and its
  norm
  is called an \define{inner product space}
  or \define{pre-Hilbert space}. A \define{Hilbert space} is
  a pre-Hilbert space which is also \putindex{complete}.
\end{Definition}

\begin{example}
  For any positive integer, the space $\R^n$ equipped with the
  Euclidean inner product
  \begin{gather*}
    \scal(x,y) = \sum_{i=1}^n x_i y_i
  \end{gather*}
  is a Hilbert space. The same holds for $\mathbb C^n$ and
  \begin{gather*}
    \scal(x,y) = \sum_{i=1}^n x_i \overline{y_i}.
  \end{gather*}
\end{example}

\begin{example}
  The spaces $\ell^2(\R)$ and $\ell^2(\mathbb C)$ of sequences
  $\{x_k\}_{k=1,\dots}$ of real and complex numbers, respectively, are
  Hilbert spaces, if equipped with the inner product
  \begin{gather*}
    \scal(x,y) = \sum_{i=k}^\infty x_k \overline{y_k}
    = \lim_{n\to\infty}\sum_{k=1}^n x_k \overline{y_k}.
  \end{gather*}
  An example for a sequence in $\ell^2(\R)$ is for instance the
  sequence $v = \{1/k\}$, since
  \begin{gather*}
    \norm{v}^2 = \sum_{i=k}^\infty \frac1{k^2} < \infty.
  \end{gather*}
  The sequence $w = \{1\}$ is not, since it does not converge
  quadratically.
\end{example}

\begin{Problem}{l2-Cauchy}
  Show that the sequence of sequences defined by
  \begin{gather*}
    v_n = \left\{1,\tfrac12,\dots,\tfrac1n,0,\dots,0\right\},
  \end{gather*}
  is a Cauchy sequence in $\ell^2$.
\end{Problem}

\begin{example}
  On the space of continuous functions on the interval
  $[-\pi/2,\pi/2]$ define the inner product
  \begin{gather*}
    \scal(f,g) = \int_{-\pi/2}^{\pi/2} f(x)g(x)\,dx.
  \end{gather*}
  Let
  \begin{gather*}
    V = \bigl\{f\in C[-\pi/2,\pi/2] \big| \scal(f,f) < \infty \bigr\}.
  \end{gather*}
  Then $V$ is a vector space with an inner product and thus a
  pre-Hilbert space, but it is not a Hilbert space, since for any $n$
  the sum
  \begin{gather*}
    f_n(x) = \frac4\pi \sum_{k=1}^n \frac{\sin\bigl((2k-1) x\bigr)}{2k-1}
  \end{gather*}
  is continuous, but
  \begin{gather*}
    \lim_{n\to\infty} f_n =
    \begin{cases}
      -1 & x<0 \\
      0 & x=0 \\
      1 & x>0
    \end{cases}
  \end{gather*}
  is not.
\end{example}

\begin{Definition}{separable}
  A subset $M$ of a Hilbert space $V$ is called \define{dense}, if
  every vector in $V$ is an accumulation point of $M$, that is, $V$ is
  the closure of $M$.  A Hilbert space is called \define{separable},
  if it has a countable dense subset.
\end{Definition}

\begin{remark}
  From the point of view of numerical analysis and computation, spaces
  which are not separable are of limited interest. In fact, every
  result of a numerical calculation is in a finite set. When we look
  at convergence for $n\to\infty$ or $h\to 0$, we are usually studying
  sequences with countable index sets. Therefore, vectors in
  nonseparable spaces cannot be approximated reliably.

  Apart from this remark, it is a goal of these notes to develop a
  framework for applied mathematics without recourse to the axiom of
  choice. Separable spaces allow us for instance to construct bases
  instead of deducing their existence indirectly.
\end{remark}

\begin{Definition}{schauder-basis}
  Let $V$ be a Hilbert space over a field $\mathbb K$. A
  \define{Schauder basis} or short \define{basis} of $V$ is a set
  $\{x_i\}$ of linearly independent vectors with coefficients $i\in I$
  from an index set $I$, such that each $v\in V$ has a representation
  of the form
  \begin{gather*}
    v = \sum_{i\in I} \alpha_i x_i,
  \end{gather*}
  with coefficients $\alpha_i \in \mathbb K$. The index set $I$ may be
  finite in the case of a finite dimensional vector space, or
  countable if $V$ is infinite dimensional and separable. In the
  latter case it is required that the sum in the linear combination
  exists as the limit of a series. In particular, the sum must be a
  Cauchy-sequence with respect to the norm of $V$.
\end{Definition}

\begin{remark}
  In the infinite dimensional case, the norm of the vector space is
  part of the definition of the basis. This is the usual view in
  functional analysis, but it fails if no norm is defined on a general
  vector space $V$. In that case, only finite sums can be admitted,
  leading to a \define{Hamel basis}. While these seem to be more
  immediate extensions of bases on finite dimensional spaces, we will
  not have good use for them here.

  We will use the concept of orthogonality below to 
\end{remark}

\begin{notation}
  We will use the term \putindex{sequence} to denote an at most
  countable set. The elements of a sequence are numbered by indices
  and the index set is $\mathbb N$ or a subset thereof.
\end{notation}

\begin{Theorem}{Banach-basis}
  Every separable Banach space has an at most countable Schauder basis.
\end{Theorem}

\begin{proof}
  See e.g.~\cite{Yosida80}. The proof is constructive and uses the
  Gram--Schmidt procedure. First, let $M$ be a countable dense subset
  of $V$, which exists due to the separability assumption. Now choose
  any numbering of $M$ and $v_1$ the first nonzero element in
  $M$. For $i=2,\dots,\infty$ choose with $v_1,\dots,v_{i-1}$ given
  $v_i$ as the next vector in $M$ which is not in the subspace spanned
  by $v_1,\dots,v_{i-1}$. This procedure generates an at most
  countable sequence $\{v_i\}$ of linearly independent vectors. It
  will only stop, if $V$ is finite dimensional, and we have that every
  element in $M$ can be written as a finite linear combination of
  vectors $v_i$.
  
  The sequence $\{v_i\}$ is a Schauder basis for $V$. In fact, given a
  vector $v\in V$ we have to show that for every $\epsilon$, there is
  a finite linear combination $s_n = \sum_{i=1}^n \alpha_i v_i$ such
  that $\norm{v-s_n} < \epsilon$. Let by separability $w_\epsilon$ in
  $M$ be such that $\norm{v-w_\epsilon} < \epsilon$. Since
  $w_\epsilon in M$, there is $n$ such that $s_n = w_\epsilon$.
\end{proof}


\subsection{Orthogonality}

\begin{Definition}{orthogonal}
  Let $V$ be an inner product space over a field $\mathbb K$. Two
  vectors $x,y\in V$ are called orthogonal if $\scal(x,y) = 0$. We
  write $x\perp y$. Let $W$ be a subspace of $V$. Then, a vector $v$
  is orthogonal to $W$, if it is orthogonal to every vector in $W$.

  A set of nonzero mutually orthogonal vectors
  $\{x_i\} \subset V$ is called \define{orthogonal set}. If
  additionally $\norm{x_i} = 1$ for all vectors, it is called an
  \define{orthonormal set}. These notions transfer directly from
  finite to countable sets.
\end{Definition}

\begin{Definition}{orthogonal-complement}
  Let $W\subset V$ be a subspace of a Hilbert space $V$. We define its
  \define{orthogonal complement} $\ortho W\subset V$ by
  \begin{gather}
    \label{eq:infsup:7}
    \ortho W = \bigl\{v\in V \big| \scal(v,w)_{V} = 0
    \;\forall\,w\in W\bigr\}.
  \end{gather}
\end{Definition}

\begin{Lemma}{orthogonal-closed}
  The the orthogonal complement $\ortho W$ of a subspace $W\subset V$
  is closed.
\end{Lemma}

\begin{proof}
  By the \putindex{Bunyakovsky-Cauchy-Schwarz inequality}, the inner
  product is continuous on $V\times V$. Therefore, the mapping
  \begin{align*}
    \phi_w\colon V &\to \R,\\
    v&\mapsto \scal(v,w),
  \end{align*}
  is continuous. For any $w\in W$, the kernel of $\phi_w$ is closed as
  the pre-image of the closed set $\{0\}$. Since
  \begin{gather*}
    \ortho W = \bigcap_{w\in W} \ker{\phi_w},
  \end{gather*}
  it is closed as the intersection of closed sets.
\end{proof}

\begin{Theorem}{orthogonal-complement}
  Let $W$ be a subspace of a Hilbert space $V$ and $W^\perp$ its
  orthogonal complement. Then, $W^\perp = \overline{W}^\perp$. Further,
  $V = W \oplus W^\perp$ if and only if $W$ is closed.
\end{Theorem}

\begin{proof}
  Clearly, $\overline{W}^\perp \subset W^\perp$ since
  $W\subset\overline{W}$. Let now $u\in W^\perp$. Then, $\phi =
  \scal(u,\cdot)$ is a continuous linear functional on $V$. Therefore,
  if a sequence $w_n \subset W$ converges to $w\in \overline{W}$, we
  have
  \begin{gather*}
    \scal(u,w) = \lim_{n\to\infty} \scal(u,w_n) = 0.
  \end{gather*}
  Hence, $u\in \overline{W}^\perp$ and $W^\perp = \overline{W}^\perp$.

  Now, the ``only if'' follows by the fact, that if $W$ is not
  closed, there is an element $w\in \overline{W}$ but not in $W$ such that
  $\scal(w,u)=0$ for all $u\in W^\perp$. Thus, $w\not\in W^\perp$ and
  consequently $w\not\in W^\perp \oplus W$.

  Let now $W$ be closed. We show that there is a unique decomposition
  \begin{gather}
    \label{eq:infsup:8}
    v = w + u,\qquad w\in W, \;u\in W^\perp,
  \end{gather}
  which is equivalent to $V = W \oplus W^\perp$. Uniqueness follows,
  since
  \begin{gather*}
    v = w_1+u_1 = w_2+u_2
  \end{gather*}
  implies that for any $y\in V$
  \begin{gather*}
    0 = \scal(w_1-w_2+u_1-u_2,y) = \scal(w_1-w_2,y) + \scal(u_1-u_2,y).
  \end{gather*}
  Choosing $y=u_1-u_2$ and $w_1-w_2$ in turns, we see that one of the
  inner products vanishes for orthogonality and the other implies that
  the difference is zero.

  If $v\in W$, we choose $w=v$ and $u=0$. For $v\not\in W$, we prove
  existence by considering that due to the closedness of $W$ there holds
  \begin{gather*}
    d=\inf_{w\in W} \norm{v-w} >0.
  \end{gather*}
  Let $w_n$ be a minimizing sequence. Using the parallelogram identity
  \begin{gather*}
    \norm{a+b}^2+\norm{a-b}^2 = 2\norm{a}^2+2\norm{b}^2,
  \end{gather*}
  we prove that $\{w_n\}$ is a Cauchy sequence by
  \begin{align*}
    \norm{w_m-w_n}^2 &= \norm{(v-w_n)-(v-w_m)}^2\\
    &= 2\norm{v-w_n}^2+2\norm{v-w_m}^2-\norm{2v-w_m-w_n}^2\\
    &= 2\norm{v-w_n}^2+2\norm{v-w_m}^2-4\norm*{v-\frac{w_m+w_n}2}^2\\
    &\le 2\norm{v-w_n}^2+2\norm{v-w_m}^2-4d^2,
  \end{align*}
  since $(w_m+w_n)/2\in W$ and $d$ is the infimum. Now we use the
  minimizing property to obtain
  \begin{gather*}
    \lim_{m,n\to\infty}\norm{w_m-w_n}^2 = 2d^2-2d^2 -4d^2=0.
  \end{gather*}
  By completeness of $V$, $w=\lim w_n$ exists and by the closedness of
  $W$, we have $w\in W$. Let $u=v-w$. By continuity of the norm, we
  have $\norm{u}=d$. It remains to show that $u\in W^\perp$. To this
  end, we introduce the variation $w+\epsilon \tilde w$ with $\tilde
  w\in W$ to obtain
  \begin{align*}
    d^2 &\le \norm{v-w-\epsilon \tilde w}^2\\
    &= \norm{u}^2-2\epsilon\scal(u,\tilde w)+\epsilon^2 \norm{\tilde w},
  \end{align*}
  implying for any $\epsilon>0$
  \begin{gather*}
    0\le-2\epsilon\scal(u,\tilde w)+\epsilon^2 \norm{\tilde w},
  \end{gather*}
  which requires $\scal(u,\tilde w) = 0$.
\end{proof}

\begin{Corollary}{ortho-density}
  A subspace $W$ of a Hilbert space $V$ is dense in $V$ if and only if
  $\ortho W = \{0\}$.
\end{Corollary}

\begin{proof}
  The ``only if'' is an immediate application of
  \blockref{Theorem}{orthogonal-complement}. For the opposite
  direction, assume $\overline W \neq V$. Choose $v\in V$ such that
  $v\not\in \overline W$. By
  \blockref{Theorem}{orthogonal-complement}, there are unique elements
  $w\in W$ and $u\in \ortho W$, such that $v=w+u$. In particular,
  $u\neq 0$.
  \begin{todo}
    Make this a lemma about  the fact that on the polar space!!
    Now, let $\phi = \scal(u,.) \in V^*$. Then, there holds
    \begin{align*}
      \phi(u) &= \norm{u}_V^2 \neq 0 \\
      \phi(w) &= 0 \quad\forall w\in W.
    \end{align*}
    Thus, from the fact that $W$ is not dense follows the existence of a
    linear functional which vanishes on $W$, but not on $V$.
  \end{todo}
\end{proof}

\begin{Definition}{ortho-projection}
  Let $W$ be a closed subspace of the Hilbert space $V$ and $\ortho W$
  be its orthogonal complement. Then, the
  \define{orthogonal projection} operators
  \begin{gather}
    \begin{split}
      \Pi_W &\colon V\to W\\
      \Pi_{\ortho W} &\colon V\to \ortho W\\
    \end{split}
  \end{gather}
  are defined by the unique decomposition
  \begin{gather}
    v = \Pi_W v + \Pi_{\ortho W} v.
  \end{gather}
\end{Definition}

\begin{Lemma}{gram-schmidt}
  \index{Gram--Schmidt} For every linearly independent sequence of
  vectors $\{v_i\}$ there is an up to scaling unique orthonormal set
  $\{x_i\}$ with the property that
  \begin{gather*}
    \forall n\in \mathbb N:\quad
    \operatorname*{span}_{i=1,\dots,n} \{x_i\}
    =
    \operatorname*{span}_{i=1,\dots,n} \{v_i\}.
  \end{gather*}
\end{Lemma}

\begin{proof}
  The proof uses induction over the length of the sequence.  Beginning
  with $v_1$, choose $x_1 = v_1$, which is nonzero by the assumption
  of linear independence.

  Assume now that the lemma holds for the elements $v_1,\dots,v_k$, such that
  \begin{gather*}
    V_k = \spann{v_1,\dots,v_k} = \spann{x_1,\dots,x_k}.
  \end{gather*}
  Again, by linear independence, $v_{k+1}$ is not in $V_k$ and $V_k$
  is closed since it is finite dimensional. Hence, we can choose
  \begin{gather*}
    \tilde x_{k+1} = \Pi_{\ortho V_k} v_{k+1},
    \qquad \frac{\tilde x_k}{\norm{\tilde x_k}}.
  \end{gather*}
\end{proof}

  
\begin{Theorem}{Hilbert-basis}
  Every separable Hilbert space has an at most countable, orthonormal basis.
\end{Theorem}

\begin{Theorem}{Hilbert-basis-completion}
  Let $W$ be a closed subspace of a separable Hilbert space $V$ and
  $\{x_k\}$ be an orthonormal basis for $W$. Then, this basis can be
completed to be a basis of $V$.
\end{Theorem}

\begin{Problem}{Schauder-basis-completion}
  \begin{enumerate}
  \item Prove \blockref{Theorem}{Hilbert-basis-completion}.
  \item Prove \blockref{Theorem}{Hilbert-basis-completion}. Take into account
  that $W$ is not assumed finite dimensional.
  \end{enumerate}
\end{Problem}

\begin{example}
  In the Hilbert spaces $\R^n$, $\mathbb C^n$, $\ell^2(\R)$, and
  $\ell^2(\mathbb C)$, an orthonormal basis is obtained by choosing
  basis vectors $x_i$ with entries $x_{i,j} = \delta_{ij}$.
\end{example}

\section{Linear operators}

\begin{intro}
  Linear mappings are the next central topic of linear algebra, which
  we want to extend to infinite dimensional spaces. Here, the basic
  definition remains the same, that is, a \define{linear operator} is
  a mapping of a Hilbert space $V$ to a Hilbert space $W$ which is
  compatible with vector operations. But Hilbert spaces have
  additional structure by their norms and their completeness.
\end{intro}

\begin{Definition}{linear-operator}
  Let $V,W$ be two vector spaces. A \define{linear mapping} or
  \define{linear operator} $L\colon V\to W$ is a mapping such that
  \begin{gather*}
    L(\alpha u+\beta v) = \alpha L(u) + \beta L(v),
  \end{gather*}
  for all $\alpha,\beta\in\mathbb K$ and for all $u,v\in V$.
%  such that  $L(u)$ and $L(v)$ are defined.
\end{Definition}

\begin{Definition}{bounded-operator}
  A linear operator $L\colon V\to W$ is called \define{bounded} on $V$
  if there exists a constant $c$ such that
  \begin{gather}
    \norm{L v}_W \le c \norm{v}_V
    \quad\forall v\in V.
  \end{gather}
  We define the operator norm $\norm{L}$ as
  \begin{gather}
    \norm L = \sup_{v\in V} \frac{\norm{L v}_W}{\norm{v}_V}.
  \end{gather}
\end{Definition}

\begin{remark}
  Every linear mapping of a finite dimensional space is continuous,
  even \putindex{Lipschitz continuous}. This follows easily from the
  matrix representation. The fact that a linear mapping can be
  unbounded is a new property of infinite dimensional spaces.
\end{remark}

\begin{Theorem}{continuous-operator}
  A linear operator $L\colon V\to W$ is continuous on $V$ if and only
  if it is bounded. It is continuous everywhere if it is continuous in
  a single point.
\end{Theorem}

\begin{todo}
  \begin{proof}
    
  \end{proof}
\end{todo}

\begin{example}
  Let $\phi:\ell^2(\R)\to\ell^2(\R)$ be such that
  \begin{gather*}
    v =
    \begin{pmatrix}
      x_1 \\ x_2 \\ \vdots \\ x_k \\ \vdots
    \end{pmatrix}
    \mapsto \phi(v) =
    \begin{pmatrix}
      x_1 \\ 4x_2 \\ \vdots \\ k^2x_k \\ \vdots
    \end{pmatrix}.
  \end{gather*}
  Clearly, $\phi$ is linear. But if we consider the sequence of
  vectors $v_n = \{\delta_{nk}\}$, we see that $v_n \mapsto n^2 v_n$ and
  thus, while the sequence is bounded in $\ell^2(\R)$, its image is
  not.
  
  Moreover, take now the sequence of sequences
  \begin{gather*}
    v_n = \left\{1,\tfrac12,\dots,\tfrac1n,0,\dots,0\right\}
    \quad \mapsto \quad \phi(v_n) = \{1,2,\dots,n,0,\dots,0\}.
  \end{gather*}
  The sequence $v_n$ converges to a limit $v \in \ell^2(\R)$, while
  the sequence $\phi(v_n)$ diverges. While $\phi(v_n)$ is defined for
  all $v_n$, it is not bounded for the limit $v$.
\end{example}

\begin{remark}
  By virtue of completeness of the space, whenever a linear operator
  is not bounded, it must be undefined for some vectors. We could
  exclude such operators from our considerations, but we would
  severely limit the theory we want to develop. Instead, we will
  accept the fact, that we have to extend the notion of a linear
  mapping $\phi: V\to W$ to a linear operator $\phi: V\to W$, which
  may not be defined on all of $V$. The following definition fixes
  this problem somewhat.
\end{remark}

\begin{Definition}{operator-domain}
  Let $\phi: V\to W$ be a linear operator. Then, the \define{domain}
  of $\phi$ is
  \begin{gather*}
    \mathcal D(\phi) = \bigl\{ v\in V \big|
    \phi(v) \in W \bigr\}.
  \end{gather*}
  Here, $\phi(v) \in W$ implies that $\phi(v)$ is also well defined.
\end{Definition}

\section{The dual space}

\begin{Definition}{dual-space}
  A linear functional on a vector space $V$ is a linear mapping from
  $V$ to $\mathbb K$.

  The \define{dual space} $V^*$ of a vector space $V$, also called the
  \define{normed dual}, is the space of all bounded linear functionals
  on $V$ equipped with the norm
  \begin{gather}
    \norm{\phi}_{V^*} = \sup_{v\in V} \frac{\phi(v)}{\norm{v}_V}.
  \end{gather}
\end{Definition}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
