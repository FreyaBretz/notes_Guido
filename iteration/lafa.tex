
\begin{intro}
  Linear algebra deals with abstract vector spaces, but most results
  on linear mappings are restricted to finite dimensional spaces,
  since they exploit the fact that we can choose a basis of finite
  length. After such a choice, every linear mapping is well-defined by
  assigning its values on the finite set of basis vectors. Thus,
  vector spaces and linear mappings, while typically sets with
  infinitely many elements, can be characterized completely by finite
  sets. The resulting theory yields very strong results by simple means.

  The choice of a basis becomes a more involved endeavor if we allow
  for spaces that do not have a finite basis. We can actually go by
  two very different routes. The route of Hamel bases, which are bases
  of inifintely many vectors, but in order to represent a vector in
  such a basis, we only allow for finite linear combinations.
  
  The other route defines a Schauder basis as a set of vectors, such
  that every vector in the space is the linear combination of
  infinitely many basis vectors. In order to define such a linear
  combination, we have to define the meaning of such an infinite sum,
  namely the convergence of the sum. In the course of such a
  definition, we will learn about a natural extension of
  Euclidean\footnote{We will not distinguish between
    Euclidean real spaces and unitary complex spaces.}
  spaces, namely pre-Hilbert and Hilbert spaces.

  Hilbert spaces share with $\R^n$ the concept of orthogonality. Thus,
  they allow us to define orthogonal bases. Furthermore, they admit
  simple generalizations of the theorem, that for any matrix $A$ with
  $n$ columns there exists an orthogonal decomposition
  \begin{gather}
    \R^n = \ker A \oplus \range{A^T}.
  \end{gather}
\end{intro}

\section{Hilbert spaces and their duals}

\begin{Definition}{inner-product}
  Let $V$ be a vector space over $\mathbb K$ with $\mathbb K = \mathbb
  C$ or $\mathbb K = \R$. An \define{inner product} on $V$ is a mapping
  $\scal(.,.): V\times V \to \mathbb K$ with the properties
  \begin{xalignat}2
    \scal(\alpha x+y,z) &= \alpha \scal(x,z) + \scal(y,z)
    && \forall x,y,z \in V; \alpha \in \mathbb K\\
    \scal(x,y) &= \overline{\scal(y,x)} && \forall x,y \in V \\
    \scal(x,x) & \ge 0 \quad\forall x\in V &\text{and}
    & \scal(x,x)=0 \Leftrightarrow x=0,
  \end{xalignat}
  usually referred to as (bi-)linearity, symmetry, and
  definiteness. We note that linearity in the second argument follows
  immediately by symmetry.
\end{Definition}

\begin{Definition}{hilbert-space}
  A vector space $V$ equipped with an inner product $\scal(.,.)$ and a
  norm defined by
  \begin{gather*}
    \norm{v} = \sqrt{\scal(v,v)}
  \end{gather*}
  is called an \define{inner product space}
  or \define{pre-Hilbert space}. A \define{Hilbert space} is
  a pre-Hilbert space which is also \putindex{complete}, that is,
  every \putindex{Cauchy sequence} with elements in the space has a
  limit in the space.
\end{Definition}

\begin{example}
  For any positive integer, the space $\R^n$ equipped with the
  Euclidean inner product
  \begin{gather*}
    \scal(x,y) = \sum_{i=1}^n x_i y_i
  \end{gather*}
  is a Hilbert space. The same holds for $\mathbb C^n$ and
  \begin{gather*}
    \scal(x,y) = \sum_{i=1}^n x_i \overline{y_i}.
  \end{gather*}
\end{example}

\begin{example}
  The spaces $\ell^2(\R)$ and $\ell^2(\mathbb C)$ of sequences
  $\{x_k\}_{k=1,\dots}$ of real and complex numbers, respectively, are
  Hilbert spaces, if equipped with the inner product
  \begin{gather*}
    \scal(x,y) = \sum_{i=k}^\infty x_k \overline{y_k}
    = \lim_{n\to\infty}\sum_{k=1}^n x_k \overline{y_k}.
  \end{gather*}
  An example for a sequence in $\ell^2(\R)$ is for instance the
  sequence $v = \{1/k\}$, since
  \begin{gather*}
    \norm{v}^2 = \sum_{i=k}^\infty \frac1{k^2} < \infty.
  \end{gather*}
  The sequence $w = \{1\}$ is not, since it does not converge
  quadratically.
\end{example}

\begin{example}
  On the space of continuous functions on the interval
  $[-\pi/2,\pi/2]$ define the inner product
  \begin{gather*}
    \scal(f,g) = \int_{-\pi/2}^{\pi/2} f(x)g(x)\,dx.
  \end{gather*}
  Let
  \begin{gather*}
    V = \bigl\{f\in C[-\pi/2,\pi/2] \big| \scal(f,f) < \infty \bigr\}.
  \end{gather*}
  Then $V$ is a vector space with an inner product and thus a
  pre-Hilbert space, but it is not a Hilbert space, since for any $n$
  the sum
  \begin{gather*}
    f_n(x) = \frac4\pi \sum_{k=1}^n \frac{\sin\bigl((2k-1) x\bigr)}{2k-1}
  \end{gather*}
  is continuous, but
  \begin{gather*}
    \lim_{n\to\infty} f_n =
    \begin{cases}
      -1 & x<0 \\
      0 & x=0 \\
      1 & x>0
    \end{cases}
  \end{gather*}
  is not.
\end{example}

\begin{Definition}{separable}
  A subset $M$ of a Hilbert space $V$ is called \define{dense}, if
  every vector in $V$ is an accumulation point of $M$, that is, $V$ is
  the closure of $M$.  A Hilbert space is called \define{separable},
  if it has a countable dense subset.
\end{Definition}

\begin{remark}
  From the point of view of numerical analysis and computation, spaces
  which are not separable are of limited interest. In fact, every
  result of a numerical calculation is in a finite set. When we look
  at convergence for $n\to\infty$ or $h\to 0$, we are usually studying
  sequences with countable index sets. Therefore, vectors in
  nonseparable spaces cannot be approximaetd reliably.
\end{remark}

\begin{Definition}{schauder-basis}
  Let $V$ be a Hilbert space over a field $\mathbb K$. A
  \define{Schauder basis} or short \define{basis} of $V$ is a set
  $\{x_i\}$ of linearly independent vectors with coefficients $i\in I$
  from an index set $I$, such that each $v\in V$ has a representation
  of the form
  \begin{gather*}
    v = \sum_{i\in I} \alpha_i x_i,
  \end{gather*}
  with coefficients $\alpha_i \in \mathbb K$. The index set $I$ may be
  finite in the case of a finite dimensional vector space, or
  countable if $V$ is infinite dimensional and separable. In the
  latter case it is required that the sum in the linear combination
  exists as the limit of a series. In particular, the sum must be a
  Cauchy-sequence with respect to the norm of $V$.
\end{Definition}

\begin{remark}
  In the infinite dimensional case, the norm of the vector space is
  part of the definition of the basis. This is the usual view in
  functional analysis, but it fails if no norm is defined on a general
  vector space $V$. In that case, only finite sums can be admitted,
  leading to a \define{Hamel basis}. While these seem to be more
  immediate extensions of bases on finite dimensional spaces, we will
  not have good use for them here.
\end{remark}

\begin{notation}
  We will use the term \putindex{sequence} to denote an at most
  countable set. The elements of a sequence are numbered by indices
  and the index set is $\mathbb N$ or a subset thereof.
\end{notation}

\begin{Definition}{linear-operator}
  Let $V,W$ be two vector spaces. A \define{linear mapping} or
  \define{linear operator} $L\colon V\to W$ is a mapping such that
  \begin{gather*}
    L(\alpha u+\beta v) = \alpha L(u) + \beta L(v),
  \end{gather*}
  for all $\alpha,\beta\in\mathbb K$ and for all $u,v\in V$ such that
  $L(u)$ and $L(v)$ are defined.
\end{Definition}

\begin{remark}
  The last subclause of the previous definition seems to be nonsense,
  and in a way, it is. Nevertheless, we will see later that it is
  actually a good idea to allow for linear operators, which are
  well-defined only on a subset of $V$.
\end{remark}

\begin{Definition}{bounded-operator}
  A linear operator $L\colon V\to W$ is called \define{bounded} on $V$
  if there exists a constant $c$ such that
  \begin{gather}
    \norm{L v}_W \le c \norm{v}_V
    \quad\forall v\in V.
  \end{gather}
  We define the operator norm $\norm{L}$ as
  \begin{gather}
    \norm L = \sup_{v\in V} \frac{\norm{L v}_W}{\norm{v}_V}.
  \end{gather}
\end{Definition}


\begin{Definition}{dual-space}
  A linear functional on a vector space $V$ is a linear mapping from
  $V$ to $\mathbb K$.

  The \define{dual space} $V^*$ of a vector space $V$, also called the
  \define{normed dual}, is the space of all bounded linear functionals
  on $V$ equipped with the norm
  \begin{gather}
    \norm{\phi}_{V^*} = \sup_{v\in V} \frac{\phi(v)}{\norm{v}_V}.
  \end{gather}
\end{Definition}

\subsection{Orthogonality}

\begin{Definition}{orthogonal}
  Let $V$ be an inner product space over a field $\mathbb K$. Two
  vectors $x,y\in V$ are called orthogonal if $\scal(x,y) = 0$. We
  write $x\perp y$. Let $W$ be a subspace of $V$. Then, a vector $v$
  is orthogonal to $W$, if it is orthogonal to every vector in $W$.

  A set of nonzero mutually orthogonal vectors
  $\{x_i\} \subset V$ is called \define{orthogonal set}. If
  additionally $\norm{x_i} = 1$ for all vectors, it is called an
  \define{orthonormal set}. These notions transfer directly from
  finite to countable sets.
\end{Definition}

\begin{Definition}{polar-orthogonal}
  Let $W\subset V$ be a subspace of a Hilbert space $V$. We define its
  \define{polar space} $W^0\subset V^*$ and its
  \define{orthogonal complement} $W^\perp\subset V$ by
  \begin{gather}
    \label{eq:infsup:7}
    \begin{split}
    W^0 &= \bigl\{f\in V^* \big| \scal(f,w)_{V^*\times V} = 0
    \;\forall\,w\in W\bigr\},
    \\
    W^\perp &= \bigl\{v\in V \big| \scal(v,w)_{V} = 0
    \;\forall\,w\in W\bigr\}.
    \end{split}
  \end{gather}
\end{Definition}

\begin{Lemma}{orthogonal-closed}
  The polar space $W^0$ and the orthogonal complement $W^\perp$ of a
  subspace $W\subset V$ are both closed.
\end{Lemma}

\begin{proof}
  Consider the mapping
  \begin{align*}
    \Phi_w\colon V^* &\to \R,\\
    v&\mapsto \scal(v,w)_{V^*\times V}.
  \end{align*}
  For any $w$, the kernel of $\phi$ is closed as
  the pre-image of a closed set. $W^0$ is closed since it is the
  intersection of these kernels for all $w\in W$.

  The inner product is continuous on $V\times V$. Therefore, the
  mapping
  \begin{align*}
    \phi_w\colon V &\to \R,\\
    v&\mapsto \scal(v,w),
  \end{align*}
  is continuous. The argument continues as above.
\end{proof}

\begin{Theorem}{orthogonal-complement}
  Let $W$ be a subspace of a Hilbert space $V$ and $W^\perp$ its
  orthogonal complement. Then, $W^\perp = \overline{W}^\perp$. Further,
  $V = W \oplus W^\perp$ if and only if $W$ is closed.
\end{Theorem}

\begin{proof}
  Clearly, $\overline{W}^\perp \subset W^\perp$ since
  $W\subset\overline{W}$. Let now $u\in W^\perp$. Then, $\phi =
  \scal(u,\cdot)$ is a continuous linear functional on $V$. Therefore,
  if a sequence $w_n \subset W$ converges to $w\in \overline{W}$, we
  have
  \begin{gather*}
    \scal(u,w) = \lim_{n\to\infty} \scal(u,w_n) = 0.
  \end{gather*}
  Hence, $u\in \overline{W}^\perp$ and $W^\perp = \overline{W}^\perp$.

  Now, the ``only if'' follows by the fact, that if $W$ is not
  closed, there is an element $w\in \overline{W}$ but not in $W$ such that
  $\scal(w,u)=0$ for all $u\in W^\perp$. Thus, $w\not\in W^\perp$ and
  consequently $w\not\in W^\perp \oplus W$.

  Let now $W$ be closed. We show that there is a unique decomposition
  \begin{gather}
    \label{eq:infsup:8}
    v = w + u,\qquad w\in W, \;u\in W^\perp,
  \end{gather}
  which is equivalent to $V = W \oplus W^\perp$. Uniqueness follows,
  since
  \begin{gather*}
    v = w_1+u_1 = w_2+u_2
  \end{gather*}
  implies that for any $y\in V$
  \begin{gather*}
    0 = \scal(w_1-w_2+u_1-u_2,y) = \scal(w_1-w_2,y) + \scal(u_1-u_2,y).
  \end{gather*}
  Choosing $y=u_1-u_2$ and $w_1-w_2$ in turns, we see that one of the
  inner products vanishes for orthogonality and the other implies that
  the difference is zero.

  If $v\in W$, we choose $w=v$ and $u=0$. For $v\not\in W$, we prove
  existence by considering that due to the closedness of $W$ there holds
  \begin{gather*}
    d=\inf_{w\in W} \norm{v-w} >0.
  \end{gather*}
  Let $w_n$ be a minimizing sequence. Using the parallelogram identity
  \begin{gather*}
    \norm{a+b}^2+\norm{a-b}^2 = 2\norm{a}^2+2\norm{b}^2,
  \end{gather*}
  we prove that $\{w_n\}$ is a Cauchy sequence by
  \begin{align*}
    \norm{w_m-w_n}^2 &= \norm{(v-w_n)-(v-w_m)}^2\\
    &= 2\norm{v-w_n}^2+2\norm{v-w_m}^2-\norm{2v-w_m-w_n}^2\\
    &= 2\norm{v-w_n}^2+2\norm{v-w_m}^2-4\norm*{v-\frac{w_m+w_n}2}^2\\
    &\le 2\norm{v-w_n}^2+2\norm{v-w_m}^2-4d^2,
  \end{align*}
  since $(w_m+w_n)/2\in W$ and $d$ is the infimum. Now we use the
  minimizing property to obtain
  \begin{gather*}
    \lim_{m,n\to\infty}\norm{w_m-w_n}^2 = 2d^2-2d^2 -4d^2=0.
  \end{gather*}
  By completeness of $V$, $w=\lim w_n$ exists and by the closedness of
  $W$, we have $w\in W$. Let $u=v-w$. By continuity of the norm, we
  have $\norm{u}=d$. It remains to show that $u\in W^\perp$. To this
  end, we introduce the variation $w+\epsilon \tilde w$ with $\tilde
  w\in W$ to obtain
  \begin{align*}
    d^2 &\le \norm{v-w-\epsilon \tilde w}^2\\
    &= \norm{u}^2-2\epsilon\scal(u,\tilde w)+\epsilon^2 \norm{\tilde w},
  \end{align*}
  implying for any $\epsilon>0$
  \begin{gather*}
    0\le-2\epsilon\scal(u,\tilde w)+\epsilon^2 \norm{\tilde w},
  \end{gather*}
  which requires $\scal(u,\tilde w) = 0$.
\end{proof}

\begin{Lemma}{gram-schmidt}
  \index{Gram--Schmidt} For every linearly independent sequence of
  vectors $\{v_i\}$ there is an up to scaling unique orthogonal set
  $\{x_i\}$ with the property that
  \begin{gather*}
    \forall n\in \mathbb N:\quad
    \operatorname*{span}_{i=1,\dots,n} \{x_i\}
    =
    \operatorname*{span}_{i=1,\dots,n} \{v_i\}.
  \end{gather*}
\end{Lemma}

\begin{todo}
  \begin{proof}
    
  \end{proof}
\end{todo}

\begin{Theorem}{separable-basis}
  Every separable Hilbert space has an at most countable orthonormal basis.
\end{Theorem}

\begin{proof}
  See e.g.~\cite{Yosida80}. The proof is constructive and uses the
  Gram--Schmidt procedure. First, let $M$ be a countable dense subset
  of $V$, which exists due to the separability assumption. Now choose
  any numbering of $M$ and $v_1$ the first nonzero element in
  $M$. For $i=2,\dots,\infty$ choose with $v_1,\dots,v_{i-1}$ given
  $v_i$ as the next vector in $M$ which is not in the subspace spanned
  by $v_1,\dots,v_{i-1}$. This procedure generates an at most
  countable sequence $\{v_i\}$ of linearly independent vectors. It
  will only stop, if $V$ is finite dimensional, and we have that every
  element in $M$ can be written as a finite linear combination of
  vectors $v_i$.
  
  The sequence $\{v_i\}$ is a Schauder basis for $V$. In fact, given a
  vector $v\in V$ we have to show that for every $\epsilon$, there is
  a finite linear combination $s_n = \sum_{i=1}^n \alpha_i v_i$ such
  that $\norm{v-s_n} < \epsilon$. Let by separability $w_\epsilon$ in $M$
  be such that $\norm{v-w_\epsilon} < \epsilon$ and choose $s_n =
  w_\epsilon$.
  
  Finally, by the Gram--Schmidt procedure, we can construct an
  orthonormal set $\{x_i\}$ from the linearly independent set $\{v_i\}$.
\end{proof}

\begin{example}
  In the Hilbert spaces $\R^n$, $\mathbb C^n$, $\ell^2(\R)$, and
  $\ell^2(\mathbb C)$, an orthonormal basis is obtained by choosing
  basis vectors $x_i$ with entries $x_{i,j} = \delta_{ij}$.
\end{example}

\section{Linear operators}

\begin{intro}
  Linear mappings are the next central topic of linear algebra, which
  we want to extend to infinite dimensional spaces. Here, the basic
  definition remains the same, that is, a \define{linear operator} is
  a mapping of a Hilbert space $V$ to a Hilbert space $W$ which is
  compatible with vector operations. But Hilbert spaces have
  additional structure by their norms and their completeness.
\end{intro}

\begin{todo}
  Operators are well defined on a basis
\end{todo}

\begin{example}
  Let $\phi:\ell^2(\R)\to\ell^2(\R)$ be such that
  \begin{gather*}
    v =
    \begin{pmatrix}
      x_1 \\ x_2 \\ \vdots \\ x_k \\ \vdots
    \end{pmatrix}
    \mapsto \phi(v) =
    \begin{pmatrix}
      x_1 \\ 2x_2 \\ \vdots \\ kx_k \\ \vdots
    \end{pmatrix}.
  \end{gather*}
  Clearly, $\phi$ is linear. But if we consider the sequence of
  vectors $v_n = \{\delta_{nk}\}$, we see that $v_n \mapsto n v_n$ and
  thus, while the sequence is bounded in $\ell^2(\R)$, its image is
  not.
  
  Moreover, take now the sequence of vectors
  \begin{gather*}
    v_n = \sum_{k=1}^n \frac1k
    \quad \mapsto \quad \phi(v_n) = \sum_{k=1}^n 1.
  \end{gather*}
  The sequence $v_n$ converges to a limit $v \in \ell^2(\R)$, while
  the sequence $\phi(v_n)$ diverges. While $\phi(v_n)$ is defined for
  all $v_n$, it is not for the limit $v$.
\end{example}

\begin{Definition}{bounded-operator}
  A linear operator $\phi: V\to W$ is \textbf{bounded}\defindex{bounded
  linear operator}, if there is a constant
  $C > 0$ such that
  \begin{gather*}
    \forall v\in V: \norm{\phi(v)}_W \le C \norm{v\vphantom{()}}_V.
  \end{gather*}
\end{Definition}

\begin{remark}
  By virtue of completeness of the space, whenever a linear operator
  is not bounded, it must be undefined for some vectors. We could
  exclude such operators from our considerations, but we would
  severely limit the theory we want to develop. Instead, we will
  accept the fact, that we have to extend the notion of a linear
  mapping $\phi: V\to W$ to a linear operator $\phi: V\to W$, which
  may not be defined on all of $V$. The following definition fixes
  this problem somewhat.
\end{remark}

\begin{Definition}{operator-domain}
  Let $\phi: V\to W$ be a linear operator. Then, the \define{domain}
  of $\phi$ is
  \begin{gather*}
    \mathcal D(\phi) = \bigl\{ v\in V \big|
    \phi(v) \in W \bigr\}.
  \end{gather*}
  Here, $\phi(v) \in W$ implies that $\phi(v)$ is also well defined.
\end{Definition}



%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% End: 
