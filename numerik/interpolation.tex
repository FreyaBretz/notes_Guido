\section{Polynominterpolation}

\subsection{Definition und Konditionsabschätzung}

\begin{Definition}{lagrange-interpolation}
  Die \define{Interpolation}saufgabe nach Lagrange lautet: seien $n+1$
  paarweise verschiedene \define{Stützstellen} $x_0,\dots,x_n$ mit
  zugehörigen Funktionswerten $f_i$ gegeben. Finde ein Polynom
  $p\in \P_n$ mit der Eigenschaft
  \begin{gather}
    p(x_i) = f_i.
  \end{gather}
  Alternativ ist die Interpolationsaufgabe aufzufassen als eine Abbildung
  \begin{gather}
    \begin{split}
      I_n\colon C[a,b] &\to \P_n\\
      p(x_i) &= f(x_i),
    \end{split}
  \end{gather}
  wobei das Interval $[a,b]$ alle Stützpunkte enthält. 
  Wir nennen diese Abbildung den
  \define{Lagrange-Interpolationsoperator} oder kurz
  \define{Lagrange-Interpolation}.
\end{Definition}

\begin{Satz}{lagrange-interpolation}
  Die Interpolationsaufgabe nach Lagrange hat eine eindeutige Lösung,
  bezeichnet als (Lagrange-)\define{Interpolierende} der Funktion $f$
  \begin{gather}
    p(x;f;x_0,\dots,x_n)
  \end{gather}
\end{Satz}
\begin{proof}
  Der Beweis ist eine direkte Konsequenz des folgenden Lemmas.
\end{proof}

\begin{Lemma}{lagrange-basis}
  Seien die Punkte $x_0,\dots,x_n$ paarweise verschieden. Dann gilt
  für die \define{Lagrange-Polynome}
  \begin{gather}
    L_i(x) = L_{i;n}(x) = L_{i}(x;x_0,\dots,x_n)
    = \prod_{\substack{j=0\\j\neq i}}^n \frac{x-x_j}{x_i-x_j}
  \end{gather}
  die Eigenschaft
  \begin{gather}
    L_i(x_j) = \delta_{ij},\qquad 0 \le i,j \le n.
  \end{gather}
  Die Lagrange-Polynome sind \putindex{orthonormal} bezüglich des
  Skalarprodukts
  \begin{gather}
    \scal(p,q) = \sum_{i=0}^n p(x_i)q(x_i).
  \end{gather}
  Daher sind sie linear unabhängig und formen eine Basis von $\P_n$.
\end{Lemma}

\begin{Korollar}{lagrange-interpolation}
  Die Lagrange-Interpolation eingeschränkt auf den Raum $\P_n$ ist die
  Identität
\end{Korollar}
\begin{remark}
  Die Lagrangesche Interpolationsaufgabe kann auch als Gaußsche
  Ausgleichsrechnung mit dem obigen Skalarprodukt aufgefasst werden.
\end{remark}

\begin{Lemma}{linear-bounded}
  Sei $f\colon X \to Y$ eine lineare Abbildung zwischen Vektorräumen
  $X$ und $Y$. Dann sind folgende Aussagen äquivalent:
  \begin{enumerate}
  \item In einem beliebigen Punkt $x\in X$ gilt für das gestörte Problem
    $y+\delta y = f(x+\delta x)$ die Abschätzung
    \begin{gather}
      \norm{\delta y} \le \kappa^{\text{abs}} \norm{\delta x}
      \qquad\forall \delta x \in X.
    \end{gather}
  \item Für $y = f(x)$ gilt die Abschätzung
    \begin{gather}
      \norm{y} \le \kappa^{\text{abs}} \norm{x}
      \qquad\forall x \in X.
    \end{gather}
  \end{enumerate}
\end{Lemma}

\begin{remark}
  Es genügt also, die Konditionierung um die null zu untersuchen, was
  die Analyse vereinfacht.

  Nun gilt für eine lineare Abbildung $f(0) = 0$. In diesem Falle ist
  also die Konditionszahl für den relativen Fehler aus
  \slideref{Definition}{datenfehler}
  bzw. \slideref{Lemma}{diff-fehler} nicht sinnvoll definiert. Wir
  benutzen daher die Konditionszahlen für den absoluten Fehler. 
\end{remark}

\begin{Satz*}{lagrange-kondition}{Konditionszahl der Lagrange-Interpolation}
  Die Konditionszahl des absoluten Fehlers in der Supremumsorm der
  Lagrange-Interpolation zu den Punkten $a = x_0 < \dots < x_n = b$
  ist die \define{Lebesgue-Konstante}
  \begin{gather}
    \Lambda_{x_0,\dots,x_n} = \max_{x\in [a,b]}
    \sum_{i=0}^n \abs{L_i(x;x_0,\dots,x_n)}.
  \end{gather}
  Es gilt also
  \begin{gather}
    \max _{x\in[a,b]} \abs{I_n f(x)}
    \le \Lambda_{x_0,\dots,x_n} \max _{x\in[a,b]} \abs{f(x)}.
  \end{gather}
  Diese Abschätzung ist scharf.
\end{Satz*}

\begin{proof}
  Siehe \cite[Satz 7.3]{DeuflhardHohmann08}.
\end{proof}

\begin{Beispiel}{lagrange-kondition-equi}
  Für äquidistante Stützstellen erhält man exemplarisch die Konditionszahlen in der zweiten Spalte. Später entwickeln wir einen optimalen Satz von Stützstellen. Die Konditionszahlen dazu sind in der rechten Spalte.
  \begin{center}
    \begin{tabular}{r|rr}
      & \multicolumn{2}{c}{ $\Lambda_{0,\dots,n}$}\\
      $n$ & äquidistant & optimal\\\hline
      5 & 3.1 & 2.1\\
      10 & 30 & 2.5 \\
      15 & 512 & 2.7 \\
      20 & 10986 & 2.9
    \end{tabular}
  \end{center}
  Quelle: \cite{DeuflhardHohmann08}
\end{Beispiel}

\subsection{Rekursive Interpolation}

\begin{Lemma*}{Aitken}{Aitken}
  Für das Interpolationspolynom
  \begin{gather}
    p_{0,\dots,n}(x) = p(x;f;x_0,\dots,x_n)
  \end{gather}
  zu paarweise verschiedenen Stützstellen $x_0,\dots,x_n$ gilt die
  Rekursionsformel
  \begin{gather}
    p_{0,\dots,n}(x)
    = \frac{(x-x_0) p_{1,\dots,n}(x) - (x-x_n) p_{0,\dots,n-1}(x)}{x_n-x_0}.
  \end{gather}
\end{Lemma*}

\begin{proof}
  Der Beweis benutzt wieder Induktion. Für eine einzige Stützstelle ist das Interpolationspolynom konstant, $p_i(x) = f_i$ und daher $p_i\in P_0$.
  Sei nun $\phi(x)$ der Bruch auf der rechten Seite. Durch Induktion sehen wir sofort, dass $\phi\in \P_n$. Ferner gilt für $i=1,\dots,n-1$
  \begin{gather}
    \begin{split}
      \phi(x_i)
      &= \frac{(x_i-x_0) p_{1,\dots,n}(x_i) - (x_i-x_n)p_{0,\dots,n-1}(x_i)}{x_n-x_0}\\
      &= \frac{(x_i-x_0) f_i - (x_i-x_n) f_i}{x_n-x_0}\\
      &= f_i.
    \end{split}
  \end{gather}
  Ebenso verschwindet für $x_0$ und $x_n$ je ein Term und es gilt
  dieselbe Aussage.
\end{proof}

\begin{Algorithmus*}{Neville}{Neville}
  Sei für eine Stelle $x$ an der das Interpolationspolynom berechnet
  werden soll $p_{ik} = p_{i-k,\dots,i}(x)$ für $i\ge k$. Dann lässt
  sich $p_{0,\dots,n}(x) = p_{nn}$ rekursiv berechnen durch
  \begin{enumerate}
  \item Für $k=0$ setze
    \begin{gather}
      p_{i0} = f_i \qquad i=0,\dots,n.
    \end{gather}
  \item Für $k=1,\dots,n$ berechne
    \begin{gather}
      p_{ik} = p_{i,k-1} + \frac{x-x_i}{x_i-x_{i-k}}
      \bigl( p_{i,k-1} - p_{i-1,k-1} \bigr)
      \qquad i=k,\dots,n.
    \end{gather}
  \end{enumerate}
\end{Algorithmus*}

\begin{Definition}{newton-basis}
  Als \define{Newton-Basis} der Lagrange-Interpolation bezeichnen wir
  die Polynome
  \begin{gather}
    \omega_i(x)
    = \omega_{0,\dots,i}(x)
    = \prod_{j=0}^{i-1} (x-x_j),
    \qquad i=0,\dots,n
  \end{gather}
  wobei die leere Summe für $i=0$ den Wert 1 annehme.
\end{Definition}

\begin{Lemma}{newton-basis}
  Sei $Q_k\in \P_n$ ein Polynom dargestellt bezüglich der Newton-Basis
  durch
  \begin{gather}
    Q_k(x) = \sum_{i=0}^k a_i \omega_i(x),\qquad k=0,\dots,n.
  \end{gather}
  Dann gilt
  \begin{align}
    Q_k(x) &= Q_{k-1}(x) + a_k \omega_k(x),
  \end{align}
  und $a_k$ ist der Koeffizient vor $x^k$ in der Monomdarstellung von
  $Q_k(x)$.
\end{Lemma}

\begin{Definition}{div-diff-1}
  Als \define{dividierte Differenzen} zur
  Lagrange-Interpolationsaufgabe bezeichnen wir die rekursiv
  definierten Werte
  \begin{align}
    [x_i]f
    &= f_i \\
    [x_i,\dots,x_{i+k}]f
    &= \frac{[x_{i+1},\dots,x_{i+k}]f - [x_i,\dots,x_{i+k-1}]f}{x_{i+k}-x_i}
  \end{align}
\end{Definition}

\begin{Satz}{newton-lagrange}
  Für das Lagrange-Interpolationspolynom $p_{i,\dots,i+k}(x)$ zu den
  paarweise verschiedenen Stützpunkten $x_i,\dots,x_{i+k}$ gilt
  \begin{gather}
    p_{i,\dots,i+k}(x)
    = \sum_{j=i}^{i+k} [x_i,\dots,x_{i+k}]f\; \frac{\omega_j(x)}{\omega_i(x)}.
  \end{gather}
\end{Satz}

\begin{proof}
  In der Newton-Darstellung gilt
  \begin{gather}
    p_{i,\dots,i+k}(x) = p_{i,\dots,i+k-1}(x)
    + \alpha \frac{\omega_{i+k}(x)}{\omega_i(x)}.
  \end{gather}
  Zu zeigen ist also $\alpha = [x_i,\dots,x_{i+k}]$, was nach
  \slideref{Lemma}{newton-basis} der Koeffizient vor $x^k$ ist. Nach
  Induktionsannahme ist
  \begin{gather}
    \begin{split}
      p_{i,\dots,i+k-1}(x) &= [x_i,\dots,x_{i+k-1}]f \,x^{k-1} +\bigo(x^{k-2})\\
      p_{i+1,\dots,i+k}(x) &= [x_{i+1},\dots,x_{i+k}]f \,x^{k-1} +\bigo(x^{k-2})
    \end{split}
  \end{gather}
  Nach dem Lemma von Aitken gilt
  \begin{gather}
    p_{i,\dots,i+k} = \frac{(x-x_i)p_{i+1,\dots,i+k}
      - (x-x_{i+k})p_{i,\dots,i+k-1}}{x_{i+k} - x_i}.
  \end{gather}
  Dessen höchster Koeffizient ist aber gerade die dividierte Differenz.
\end{proof}

\begin{remark}
  Der Bruch im vorherigen Satz ist nicht problematisch, da
  \begin{gather}
    \frac{\omega_j(x)}{\omega_i(x)} = \prod_{\ell=i}^{j-1} (x-x_\ell).
  \end{gather}
\end{remark}

\begin{Satz}{Lagrange-restglied}
  Sei $x\in \R$ und $I$ das kleinste Intervall, das die Punkte $x$, $a$ und $b$
  enthält.
  Sei $f \in C^{n+1}(I)$ und $p\in \P_n$ die
  Lagrange-Interpolierende zu den Stützstellen
  $x_0,\dots,x_n \in[a,b]$. Dann gibt es einen Punkt
  $\xi\in I$, so dass
  \begin{gather}
    f(x)- p(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!} \omega_{0,\dots,n}(x).
  \end{gather}
  Wir bezeichnen diese Aussage als \define{Fehlerdarstellung}, die
  rechte Seite auch als \define{Restglied}.
\end{Satz}

\begin{proof}
  Der Beweis folgt \cite[Satz 2.1.4.1]{Stoer83}.  Zunächst bemerken
  wir, dass für alle Stützstellen $x_i$ gilt, dass
  $f(x_i) - p(x_i) = 0$. Dort ist also nichts zu beweisen.
  Sei nun
  \begin{gather}
    \label{eq:interpolation:1}
    F(y) = f(y)-p(y) - \alpha \omega_n(y)
  \end{gather}
  und $\alpha$ soll so gewählt werden, dass $F(x) = 0$. Damit hat $F(y)$ im
  Intervall $I$ insgesamt die $n+2$ Nullstellen $x,x_0,\dots,x_n$.
  Wiederholte Anwendung des Satzes von Rolle ergibt, dass $F'(y)$
  insgesamt $n+1$ Nullstellen hat und das $F^{(n+1)}(y)$ eine
  Nullstelle $\xi$ besitzt. Da $p\in \P_n$ gilt
  \begin{gather}
    0 = F^{(n+1)}(\xi) = f^{(n+1)}(\xi) - \alpha (n+1)!
  \end{gather}
  und damit
  \begin{gather}
    \alpha = \frac{f^{(n+1)}(\xi)}{(n+1)!}.
  \end{gather}
\end{proof}

\begin{Korollar}{Lagrange-restglied}
  Sei $f \in C^{n+1}[a,b]$ und alle Stützstellen $x_i$ im Intervall
  $[a,b]$. Dann gibt es $\xi\in[a,b]$, so dass
  \begin{gather}
    [x_0,\dots,x_n]f = \frac{f^{(n)}}{n!}(\xi).
  \end{gather}
\end{Korollar}

\begin{proof}
  Formel~\eqref{eq:interpolation:1} gibt gerade an, dass $\alpha$ der
  Koeffizient vor dem nächsten Newton-Basispolynom ist, wenn man den
  Punkt $x$ der Menge der Stützstellen hinzufügt.
\end{proof}

\begin{Korollar}{Lagrange-fehler-1}
  Es gelten die Voraussetzungen von
  \slideref{Satz}{Lagrange-restglied}. Dann gibt es eine Konstante
  $C$, die nur von der Wahl der Stützstellen abhängt, so dass
  \begin{gather}
    \max_{x\in[a,b]} \abs{f(x)-p_{0,\dots,n}(x)}
    \le \frac{C \abs{b-a}^{n+1}}{(n+1)!} \max_{x\in[a,b]} \abs{f^{(n+1)}(x)} 
  \end{gather}
\end{Korollar}

\begin{remark}
  Die Fehlerabschätzung in \slideref{Korollar}{Lagrange-fehler-1}
  können wir auch kürzer schreiben als
  \begin{gather}
    \norm{f-p_{0,\dots,n}}_\infty \le \frac{C \abs{b-a}^{n+1}}{(n+1)!}
    \norm{f^{(n+1)}}_{\infty}.
  \end{gather}
  Die rechte Seite besteht dabei aus dem Produkt aus einem Teil, der
  nur von den Daten abhängt, $\norm{f^{(n+1)}}_{\infty}$ und einem
  Anteil, der durch das Verfahren bestimmt ist.

  Wir sehen, dass Interpolation auf einem Intervall um so genauer ist,
  je kürzer das Intervall ist.
\end{remark}

\begin{intro}
  Der Rest dieses Abschnitts befasst sich mit der Frage, wie die
  Stützstellen $x_0,\dots,x_n$ gewählt werden können, damit die
  Konstante $C$ in der Fehlerabschätzung optimal ist.  Aus der
  Fehlerdarstellung in \slideref{Satz}{Lagrange-restglied} folgt, dass
  wir dazu ein Polynom finden müssen, dessen führender Koeffizient 1
  ist, und das minimalen Betrag auf dem Intervall $[a,b]$ hat.
  Tatsächlich erlauben uns die Tschebyscheff-Polynome, diese
  Optimalität zu erreichen.
\end{intro}

\begin{Lemma}{chebyshev-properties}
  Die Tschebyscheff-Polynome, die der Rekursionsformel in
  \slideref{Definition}{chebyshev-polynome} genügen, haben die
  Darstellung
  \begin{gather}
    T_k = \cos(k \operatorname{arccos} x)
  \end{gather}
  Insbesondere gilt
  \begin{alignat}3
    T_k(1)&=1\\
    T_k(-1) &= (-1)^k\\
    \abs{T_k(x)} &\le 1, &\quad x&\in [-1,1]\\
    T_k(x) &=(-1)^j,
                   &\quad x&=\cos\left(\frac{j}{k}\pi\right),
                   &\quad j&=0,\dots,k\\
    T_k(x) &= 0,
             &\quad x&=\cos\left(\frac{2j-1}{2k}\pi\right),
             &\quad j&=1,\dots,k
  \end{alignat}
\end{Lemma}

\begin{proof}
  Hausaufgabe
\end{proof}

\begin{Satz}{chebyshev-minimal-1}
  Jedes Polynom $p\in \P_n$ mit führendem Koeffizienten 1 nimmt im
  Intervall $[-1,1]$ einen Wert $\abs{p(x)} \ge \nicefrac1{2^{n-1}}$
  an und es gilt
  \begin{gather}
   \frac1{2^{n-1}} T_n(x)
   = \operatorname*{arg min}_{\substack{p\in\P_n\\p = x^n+\cdots}}
   \max_{x\in[-1,1]}\abs{p(x)}.
  \end{gather}
\end{Satz}

\begin{proof}
  Siehe auch \cite[Satz 7.19]{DeuflhardHohmann08}. Aus der
  Rekursionsformel folgt sofort, dass der höchste Koeffizient von
  $T_n$ den Wert $2^{n-1}$ annimmt. Sei nun als Widerspruchsannahme
  $p\in \P_n$ ein weiteres Polynom mit höchstem Koeffizienten
  $2^{n-1}$, so dass
  \begin{gather}
    \max_{x\in[-1,1]} \abs{p(x)} < 1.
  \end{gather}
  Dann ist $q_n = T_n-p \in \P_{n-1}$ und für die
  \define{Tschebyscheff-Abszisse}n
  $\tilde x_j = \cos(\nicefrac{j\pi}{n})$ mit $j=0,\dots,n$ gilt
  \begin{xalignat}4
    T_n(\tilde x_j) &= 1,
    & p(\tilde x_j) &< 1
    & q_n(\tilde x_j) &> 0,
    & j&\text{ gerade}\\
    T_n(\tilde x_j) &= -1,
    & p(\tilde x_j) &> -1
    & q_n(\tilde x_j) &< 0,
    & j&\text{ ungerade}.
  \end{xalignat}
  $q_n$ wechselt also an mindestens $n$ Stellen das Vorzeichen und hat
  damit als stetige Funktion mindestens ebensoviele Nullstellen. Aus
  $q_n\in\P_{n-1}$ folgt damit im Widerspruch $q_n=0$ und $p=T_n$.
  Damit gilt nach Skalierung um den Faktor $2^{n-1}$
  \begin{gather}
    \operatorname*{min}_{\substack{p\in\P_n\\p = x^n+\cdots}}
   \max_{x\in[-1,1]}\abs{p(x)} \ge 1,
  \end{gather}
  und Gleichheit für das skalierte Tschebyscheff-Polynom.
\end{proof}

\begin{Korollar}{Lagrange-chebychev}
  Wählt man als Stützstellen die Werte
  \begin{gather}
    x_i = \frac{a+b}2 + \frac{b-a}2 \cos\left(\frac{2i+1}{2n+2}\pi\right),
    \qquad i=0,\dots,n,
  \end{gather}
  So gilt für den Fehler der Lagrange-Interpolation
  \begin{gather}
    \norm{f-p_{0,\dots,n}}_\infty \le \frac{\abs{b-a}^{n+1}}{2^{2n}(n+1)!}
    \norm{f^{(n+1)}}_{\infty}.
  \end{gather}
\end{Korollar}

\begin{proof}
  Zunächst transformieren wir die Aufgabe vom Intervall $[a,b]$ auf
  das Intervall $[-1,1]$ durch die Abbildung
  \begin{gather}
    x = \Phi(\xi) = \frac{a+b}2 + \frac{b-a}2 \xi.
  \end{gather}
  Es gilt $\Phi(-1) = a$, $\Phi(1)=b$ und di Punkte $x_i$ sind die
  Bilder der Tschebyscheff-Abszissen $\xi_i$ zu $T_{n+1}$. Es gilt
  $\Phi'(\xi) = (b-a)/2$ und für die Funktion $F(\xi) = f(\Phi(\xi))$
  gilt
  \begin{gather}
    \frac{d^k}{d\xi^k} F(\xi) = \left(\frac{b-a}2\right)^k
    \frac{d^k}{dx^k} f(x).
  \end{gather}
  Auf $[-1,1]$ folgern wir aus \slideref{Satz}{Lagrange-restglied} und
  \slideref{Satz}{chebyshev-minimal-1}, dass für die Interpolation gilt
  \begin{gather}
    \max_{\xi\in[-1,1]} \abs{F(\xi) - P(\xi)}
    \le 2^{1-n} \max_{\xi\in[-1,1]}\abs{F^{(n+1)}(\xi)},
  \end{gather}
  woraus folgt
  \begin{gather}
    \max_{x\in[a,b]} \abs{f(x) - p(x)}
    \le 2^{1-n} \left(\frac{b-a}2\right)^{n+1} \max_{x\in[a,b]}\abs{f^{(n+1)}(x)}.
  \end{gather}  
\end{proof}
\subsection{Hermite-Interpolation und dividierte Differenzen}

\begin{Definition}{hermite-interpolation}
  Die \define{Hermite-Interpolation} benutzt neben Funktionswerten
  auch Ableitungswerte zur Interpolation. Das Interpolationspolynom
  $p\in \P_n$ genügt in $m$ paarweise verschiedenen Punkten den
  Bedingungen
  \begin{gather}
    \frac{d^j p}{dx^j}(x_i) = f_i^{j},
    \qquad i = 0,\dots, m, \quad j=0,\dots,n_i,
  \end{gather}
  und es gilt
  \begin{gather}
    \sum_{i} n_i = n+1.
  \end{gather}
  Die definierenden Funktionale\footnote{Als Funktional bezeichnet man
    eine Abbildung aus einem Vektorraum in den zugehörigen Körper}
  $\nicefrac{d^j}{dx^j} p(x_i)$ werden auch als \define{Knotenwerte}
  oder \define{Knotenfunktionale} bezeichnet.
\end{Definition}

\begin{Satz}{hermite-interpolation}
  \slideref{Definition}{hermite-interpolation} bestimmt das
  Interpolationspolynom eindeutig.
\end{Satz}

\begin{proof}
  Analog zur Lagrange-Interpolation identifizieren wir wieder eine
  Basis $\{H_{ij}(x)\}$, diesmal doppelt indiziert, die bezüglich der
  Interpolationsbedingungen orthogonal ist. Damit stellen wir das
  Interpolationspolynom dar als
  \begin{gather}
    p(x) = \sum_{i=1}^m \sum_{j=0}^{n_i-1} f_i^j H_{ij}(x).
  \end{gather}
  Zunächst führen wir die Hilfspolynome
  \begin{gather}
    q_{ij}(x) = \frac{(x-x_i)^j}{j!}\prod_{k\neq i}
    \left(\frac{x-x_k}{x_i-x_k}\right)^{n_i}
  \end{gather}
  ein. Es gilt
  \begin{gather}
    \begin{aligned}
      \frac{d^j q_i}{d x^j} (x_k) &=0,
      \quad &k\neq i,&\quad& j&=0,\dots,n_{k}-1,\\
      \frac{d^j q_i}{d x^j} (x_i) &=0,
      \qquad &&& j&=0,\dots,n_{i}-1,\\   
      \frac{d^{n_{i}-1} q_i}{d x^{n_{i}-1}} (x_i) &=1.
      \qquad &&&& 
    \end{aligned}
  \end{gather}
  Damit können wir rekursiv definieren
  \begin{gather}
    \begin{aligned}
      H_{i,n_i-1}(x) &= q_{i,n_i-1}(x)
      & i&= 1,\dots,m\\
      H_{ij}(x) &= q_{ij}(x) - \sum_{k=j+1}^{n_i-1} q_{ij}^{(k)}(x_i) q_{ik}(x),
    \end{aligned}
  \end{gather}
  wobei die letzte Zeile die Anwendung des Gram-Schmidt-Verfahrens
  ist. Per constructionem gilt für diese Basis
  \begin{gather}
    \frac{d^\ell}{dx^\ell} H_{ij}(x_k) = \delta_{ik}\delta_{j\ell}.
  \end{gather}
\end{proof}

\begin{Notation}{interpolation-ascending}
  Bei der Polynominterpolation ist die Anordnung der
  Interpolationspunkte beliebig. Das ist auch weiterhin der Fall. Für
  die Darstellung der Resultate und Beweise ist es aber oft hilfreich
  anzunehmen, dass sie in aufsteigender Folge angeordnet sind. Wir
  nehmen daher ab jetzt an, dass
  \begin{gather}
    a = x_0 \le x_1 \le \dots \le x_n = b.
  \end{gather}
  Dabei sollen $k$-fach wiederholte Stützstellen bedeuten, dass dort
  nicht nur der der Funktionswert, sondern auch die ersten $k-1$
  Ableitungen interpoliert werden. Damit haben wir für die
  Interpolation in $\P_n$ immer eine Folge von $n+1$ Stützstellen.
\end{Notation}

\begin{Beispiel}{taylor-polynom}
  Sind alle Stützstellen $x_0 = \dots = x_n$ identisch, so erhalten
  wir duch Interpolation einer Funktion $f\in C^n[a,b]$ das
  Taylor-Polynom vom Grad $n$
  \begin{gather}
    p(x;f;x_0,\dots,x_n) = \sum_{k=0}^n \frac{(x-x_0)^k}{k!} f^{(k)}(x_0).
  \end{gather}
\end{Beispiel}

\begin{Beispiel}{hermite-kubisch}
  Die kubische Hermite-Interpolation auf dem Intervall $[a,b]$ ist
  definiert durch die Knotenwerte
  \begin{gather}
    p(a), p'(a), p(b), p'(b).
  \end{gather}
\end{Beispiel}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
