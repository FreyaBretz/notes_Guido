\section{Das Newton-Verfahren}

\begin{Definition}{newton-verfahren}
  Das \define{Newton-Verfahren} ist ein Iterationsverfahren zum
  Auffinden einer Nullstelle einer Funktion $f\colon \R^n\to \R^n$. Zu
  einem Startwert $x^{(0)} \in \R^n$ berechnen sich die weiteren
  Iterierten durch
  \begin{gather}
    \label{eq:newton:1}
    x^{(k+1)} = x^{(k)} - \bigl(\nabla f(x^{(k)})\bigr)^{-1} f(x^{(k)}).
  \end{gather}
\end{Definition}

\begin{Algorithmus*}{newton}{Newton-Verfahren}
  \lstinputlisting[firstline=3,lastline=9]{code/newton.py} Die
  Parameter zu dieser Funktion sind der Startwert $x$, die Funktion
  $f(x)$, die Anwendung der inversen Ableitung
  \begin{gather}
    \operatorname{Dfinv}(x,r) = \bigl(\nabla f(x)\bigr)^{-1}r,
  \end{gather}
  sowie eine Toleranz als Abbruchkriterium.
\end{Algorithmus*}
\begin{Lemma}{newton-1}
  Sei $M\subset \R^n$ konvex. Sei $f\colon M\to \R^n$ stetig differenzierbar auf $M$ und die Ableitung genüge der Lipschitz-Abschätzung
  \begin{gather}
    \norm{\nabla f(x) - \nabla f(y)} \le \gamma \norm{x-y}
    \qquad \forall x,y\in M.
  \end{gather}
  mit einer Konstanten $\gamma$. Dann gilt für alle $x,y\in M$
  \begin{gather}
    \norm{f(x)-f(y) - \nabla f(y)(x-y)}
    \le \frac\gamma2 \norm{x-y}^2.
  \end{gather}
\end{Lemma}

\begin{proof}
  Wir folgen~\cite[Hilfssatz 5.3.1]{Stoer83}.
  Sei $\phi\colon[0,1] \to \R^n$ die Hilfsfunktion definiert durch
  \begin{gather}
    \phi(t) = f\bigl(y+t(x-y)\bigr),
  \end{gather}
  so dass
  \begin{gather}
    f(x)-f(y) - \nabla f(y)(x-y) = \phi(1) - \phi(0) - \phi'(0)
    = \int_0^1 (\phi'(t)-\phi'(0))\dt,
  \end{gather}
  denn nach der Kettenregel gilt
  \begin{gather}
    \phi'(t) = \nabla f\bigl(y+t(x-y)\bigr)(x-y).
  \end{gather}
  Den Integranden schätzen wir ab durch
  \begin{align}
    \norm{\phi'(t)-\phi'(0)}
    & = \norm{\Bigl(\nabla f\bigl(y-t(x-y)\bigr) - \nabla f(y)\Bigr)(x-y)}
    \\
    & \le \norm{\nabla f\bigl(y-t(x-y)\bigr) - \nabla f(y)}\norm{(x-y)}
    \\
    & \le \gamma\,t\norm{x-y}^2.
  \end{align}
  Einsetzen ins Integral ergibt
  \begin{gather}
    \norm{f(x)-f(y) - \nabla f(y)(x-y)}
    \le \frac\gamma2 \norm{x-y}^2.
  \end{gather}
\end{proof}

\begin{Satz}{newton-konvergenz}
  Sei $M\subset \R^n$ eine offene, konvexe Menge und
  $f\colon \overline{M} \to \R^n$ stetig differenzierbar in $M$ und
  stetig auf $\overline{M}$. Die \define{Jacobi-Matrix} $\nabla f(x)$
  sei auf ganz $M$ invertierbar und es gebe Konstanten $\beta$ und
  $\gamma$, so dass für $x,y\in M$ gilt
  \begin{gather}
    \label{eq:newton:2}
    \norm{\nabla f(x) - \nabla f(y)} \le \gamma \norm{x-y},
    \qquad \norm{\bigl(\nabla f(x)\bigr)^{-1}} \le \beta.
  \end{gather}
  Gibt es dann eine Konstante $\alpha$, so dass
  \begin{align}
    \label{eq:newton:3}
    \norm{\bigl(\nabla f(x^{(0)})\bigr)^{-1} f(x^{(0)})}
    &\le \alpha\\
    h := \frac{\alpha\beta\gamma}2 &<1\\
    \overline{B_r(x^{(0)})} &\subseteq M, \qquad\text{mit } r=\frac{\alpha}{1-h},
  \end{align}
  So ist die Folge $x^{(k)}$ des Newton-Verfahrens für alle
  $k=1,\dots$ wohldefiniert und liegt in $B_r(x^{(0)})$. Ferner
  konvergiert sie quadratisch gegen einen Wert
  $x^*\in\overline{B_r(x^{(0)})}$ und es gilt
  \begin{gather}
    \label{eq:newton:4}
    \norm{x^{(k)}-x^*} \le \alpha\frac{h^{2^k-1}}{1-h^{2^k}}.
  \end{gather}
\end{Satz}

\begin{proof}
  Wir folgen~\cite[Satz 5.3.2]{Stoer83}.
  Wir zeigen zunächst induktiv für alle $k=1,\dots$, dass das
  Folgenglied $x^{(k)}$ in $B_r(x^{(0)}) \subseteq M$ liegt. Damit
  existiert dann nach Voraussetzung
  $\bigl(\nabla f(x^{(k)})\bigr)^{-1}$ und $x^{(k+1)}$ ist
  wohldefiniert. Zur Verankerung bemerken wir, dass offensichtlich
  $x^{(0)}\in B_r(x^{(0)})$ und $x^{(1)}$ nach
  Voraussetzung~\eqref{eq:newton:3}. Nach der Verfahrensvorschrift
  können wir abschätzen:
  \begin{align}
    \norm{x^{(k+1)} - x^{(k)}}
    & = \norm{\bigl(\nabla f(x^{(k)})\bigr)^{-1} f(x^{(k)})}\\
    & \le \beta \norm{f(x^{(k)})}\\
    & = \beta \norm{f(x^{(k)}) - f(x^{(k-1)}) - \nabla f(x^{(k)})(x^{(k)}-x^{(k-1)})},
  \end{align}
  wobei wir die letzte Zeile aus der Multiplikation der
  Verfahrensvorschrift mit $\nabla f$ gewonnen haben. Hierauf wenden
  wir nun \slideref{Lemma}{newton-1} an und bekommen die quadratische
  Konvergenz, wenn der Abstand zweier Folgenglieder einmal klein genug
  ist:
  \begin{gather}
    \label{eq:newton:5}
    \norm{x^{(k+1)} - x^{(k)}}
    \le \frac{\beta\gamma}2 \norm{x^{(k)} - x^{(k-1)}}^2.
  \end{gather}
  Es bleibt zu zeigen, dass die Folge in $B_r(x^{(0)})$ bleibt. Dazu
  zeigen wir per Induktion, dass
  \begin{gather}
    \label{eq:newton:6}
    \norm{x^{(k+1)} - x^{(k)}} \le \alpha h^{2^k-1}.
  \end{gather}
  Für $k=0$ folgt $\norm{x^{(1)} - x^{(0)}} \le \alpha$ direkt
  aus~\eqref{eq:newton:3}. Für den Induktionsschritt benutzen wir
  unsere Konvergenzabschätzung~\eqref{eq:newton:5}:
  \begin{gather}
    \norm{x^{(k+1)} - x^{(k)}}
    \le \frac{\beta\gamma}2 \norm{x^{(k)} - x^{(k-1)}}^2
    \le \frac{\beta\gamma}2 (\alpha h^{2^{k-1}-1})^2
    = \frac{\alpha\beta\gamma}2 \alpha h^{2^k-2}
    = \alpha h^{2^k-1}.
  \end{gather}
  Nun können wir mit einer Teleskopsumme abschätzen
  \begin{align}
    \norm{x^{(k+1)} - x^{(0)}}
    &\le \sum_{j=0}^k \norm{x^{(j+1)} - x^{(j)}}\\
    & \le \alpha (1+h+h^3+h^7+\dots+h^{2^k-1})\\
    &<\frac\alpha{1-h} = r,
  \end{align}
  Aus~\eqref{eq:newton:6} folgt mit dieser Abschätzung, dass $x^{(k)}$
  Cauchy Folge ist und durch Grenzübergang die
  Abschätzung~\eqref{eq:newton:4}.
\end{proof}

\section{Abstiegsverfahren und Globalisierung}

\begin{intro}
  Die lokale Konvergenz ist beim Newtonverfahren ein großes Hindernis
  für die Anwendung. Wählt man den Startwert nicht im Einzugsbereich
  einer Nullstelle, so divergiert das Verfahren. Der Einzugsbereich,
  wie er sich aus dem Konvergenzsatz ergibt, ist dabei oft sehr klein
  und daher schwer zu finden.

  Ziel dieses Abschnitts ist daher, eine Modifikation des
  Newton-Verfahrens zu finden, die den Konvergenzbereich aufweitet,
  idealerweise sogar globale Konvergenz erzeugt. Solche Modifikationen
  findet man unter der Bezeichnung \define{Globalisierung}.
\end{intro}

\begin{Definition}{anstiegskegel}
  Sei $g\colon \R^n\to \R$ stetig differenzierbar. Dann definieren wir
  den Kegel positiven Anstiegs zum Parameter $\gamma$ als
  \begin{gather}
    S_\gamma(x) = \bigl\{ s\in\R^n \big|
    \norm{s} = 1 \;\wedge \;
    \nabla g(x)\cdot s \ge \gamma\norm{\nabla g(x)}
    \bigr\}.
  \end{gather}
  Die Richtung des steilsten Anstiegs im Punkt $x$ ist $\nabla g(x)$.
\end{Definition}

\begin{todo}
  Umgebung ``remark''.
\end{todo}
Da es sich um normierte Vektoren handelt, ist die Menge $S_\gamma(x)$
eigentlich kein Kegel, sondern eine Kugel in der Einheitssphäre mit
Zentrum im normierten Gradienten und Radius $\arccos \gamma$. Zusammen
mit den Skalierungsfaktoren, die unten eingeführt werden,
repräsentiert sie aber einen Kegel.


\begin{Lemma}{abstieg-reduktion}
  Sei $g\colon\R^n\to\R$ stetig differenzierbar und in einem Punkt
  $y\in\R^n$ gelte $\nabla g(y) \neq 0$. Dann gibt es eine Umgebung
  $U(y)$ und $\lambda>0$, so dass für alle $x\in U(y)$,
  $s\in S_\gamma(x)$ und $\mu\in [0,\lambda]$ gilt
  \begin{gather}
    g(x-\mu s) \le g(x) - \frac{\mu\gamma}4 \norm{\nabla g(y)}.
  \end{gather}
\end{Lemma}

\begin{proof}
  Wir definieren zunächst eine Umgebung um $y$ auf der sich die
  Gradienten nicht zu sehr unterscheiden:
  \begin{gather}
    \label{eq:newton:8}
    U_1(y) = \left\{
      x\in\R^n \middle| \;\norm{\nabla g(x)-\nabla g(y)} \le \frac\gamma4 \norm{\nabla g(y)}
      \right\}.
    \end{gather}
    Eine zweite Umgebung ist so gewählt, dass dort der Abstiegskegel
    in einem größeren Abstiegskegel im Punkt $y$ enthalten ist:
    \begin{gather}
      U_2(y) = \left\{
        x\in\R^n \middle| S_\gamma(x) \subseteq S_{\nicefrac\gamma2}(y)\right\}.
    \end{gather}

    Wähle nun $\lambda>0$, so dass
    \begin{gather}
      \overline{B_{2\lambda}(y)}\subseteq U_1(y) \cap U_2(y).
    \end{gather}
    und $U(y) = B_\lambda(y)$. Dann zeigen wir nun die Aussage für
    alle $x\in U(y)$, $s\in S_\gamma(x)$ und $\mu\in[0,\lambda]$. Nach
    dem Mittelwertsatz existiert $\theta\in(0,1)$ so dass
    \begin{gather}
      g(x)-g(x-\mu s) = \mu \nabla g(x-\theta\mu s)s.
    \end{gather}
    Wir formen weiter um:
    \begin{align}
      \nabla g(x-\theta\mu s)s
      &= \bigl(\nabla g(x-\theta\mu s) - \nabla g(y)\bigr)s + \nabla g(y)s\\
      &\ge -\frac{\gamma}4 \norm{\nabla g(y)}\norm{s} + \nabla g(y)s\\
      &\ge -\frac{\gamma}4 \norm{\nabla g(y)} + \frac\gamma2 \norm{\nabla g(y)}\\
      & \ge \frac\gamma4 \norm{\nabla g(y)}.
    \end{align}
\end{proof}

\begin{todo}
  Reihenfolge vertauschen  
\end{todo}

\begin{Definition}{abstiegsverfahren}
  Ein \define{Abstiegsverfahren} für eine stetig differenzierbare
  Funktion $g\colon \R^n\to\R$ ist eine Iterationsvorschrift aus den
  folgenden Schritten: gegeben $x^{(k)}$,
  \begin{enumerate}
  \item wähle $\gamma_k>\gamma>0$ und eine Abstiegsrichtung
    $s^{(k)} \in S_{\gamma_k}(x^{(k)})$.
  \item Wähle eine Schrittweite $\alpha_k>0$ und setze
    \begin{gather}
      x^{(k+1)} = x^{(k)} - \alpha_k s^{(k)},
    \end{gather}
    so dass die \define{Reduktionsbedingung}
    \begin{gather}
      \label{eq:newton:7}
      g\bigl(x^{(k+1)}\bigr)
      \le g\bigl(x^{(k)}\bigr) - \frac{\gamma_k\alpha_k}{4}\norm{\nabla g(x^{(k)})}
    \end{gather}
    gilt.
  \end{enumerate}
\end{Definition}

\begin{remark}
  Lemma \slideref{Lemma}{abstieg-reduktion} stellt sicher, dass es in
  jedem Schritt ein positives $\alpha_k$ gibt, das die Bedingung
  erfüllt.
\end{remark}

\begin{Beispiel*}{steepest-descent}{Verfahren des steilsten Abstiegs}
  Sei der Vektor $x^{(k)} \in\R^n$ gegeben, dann wähle
  $s^{(k)} = \nabla g(x^{(k)})$. Die Schrittweite $\alpha_k$ wird aus
  der eindimensionalen Minimierungsaufgabe (auch \define{line search}
  genannt)
  \begin{gather}
    \alpha_k = \operatorname*{argmin}_{\alpha>0}
    g\bigl(x^{(k)} - \alpha s^{(k)}\bigr)
  \end{gather}
  bestimmt. Danach setze
  \begin{gather}
    x^{(k+1)} = x^{(k)} - \alpha_k s^{(k)}.
  \end{gather}
\end{Beispiel*}

\begin{Satz}{abstieg-haeufung}
  Sei $g\colon \R^n\to \R$ und $x^{(0)} \in\R^n$ so gewählt, dass die Menge
  \begin{gather}
    K = \Bigl\{x\in\R^n \; \Big| \; g(x) \le g\bigl(x^{(0)}\bigr) \Bigr\}
  \end{gather}
  kompakt und $g$ stetig differenzierbar auf einer Umgebung von $K$
  ist. Dann besitzt die Folge $\{x^{(k)}\}$ des Abstiegsverfahrens
  mindestens einen Häufungspunkt in $K$. Gilt zusätzlich in der
  Umgebung eines Häufungspunkts $\gamma_k \ge \gamma>0$, so existiert
  $\alpha$, so dass $\alpha_k \ge \alpha>0$ gewählt werden kann. In
  diesem Fall ist der Häufungspunkt ein stationärer Punkt von $g$.
\end{Satz}

\begin{proof}
  Da die Folge monoton fällt, bleibt sie in $K$ und hat der
  Kompaktheit wegen mindestens einen Häufungspunkt $x^*$. Wir benennen
  nun ebenfalls mit $\{x^{(k)}\}$ ebenfalls eine Teilfolge, die gegen diesen
  Häufungspunkt konvergiert.

  Wir machen die Widerspruchsannahme, dass $x^*$ kein stationäre Punkt von $g$ ist, also
  \begin{gather}
    \nabla g(x^*) \neq 0.
  \end{gather}

  Wir bemerken, dass nach Voraussetzung $S_{\gamma_k}(x^*) \subseteq S_\gamma(x^*)$ gilt.
  Nun gibt es nach \slideref{Lemma}{abstieg-reduktion} eine Umgebung
  $U(x^*)$ und eine Zahl $\lambda>0$, so dass für alle $\mu\in[0,\lambda]$ gilt:
  \begin{gather}
    g(x-\mu s) \le g(x) - \mu \frac\gamma4\norm{\nabla g(x^*)}.
  \end{gather}
  Daraus folgt, dass zu jedem $\alpha_k \le \lambda$ die
  Reduktionsbedingung~\eqref{eq:newton:7} erfüllt ist und
  dementsprechend die Bedingung $\alpha_k\ge\alpha$ für
  $\alpha\le\lambda$ erfüllt werden kann.

  Sei nun $k_0$ gewählt, so dass $x^{(k)}\in U(x^*)$ für alle
  $k\ge k_0$. Dann gilt nach der Konstruktion von $U(x^*)$
  in~\eqref{eq:newton:8}, dass
  \begin{gather}
    \norm{\nabla g(x^{(k)})} \ge \norm{\nabla g(x^{*})} - \norm{\nabla g(x^{(k)}) - \nabla g(x^{*})}
    \ge \left(1-\frac\gamma4\right)  \norm{\nabla g(x^{*})}.
  \end{gather}
  Es gilt also
  \begin{gather}
    g(x^{k+1}) \le g(x^{k}) - \frac34 \alpha \norm{\nabla g(x^{*})}.
  \end{gather}
  Daraus folgt im Widerspruch zur Stetigkeit die Konvergenz
  $g(x^{(k)}) \to -\infty$, Es muss also $\nabla g(x^{*})=0$ gelten,
  $x^*$ ist also ein stationärer Punkt von $g$.
\end{proof}

\begin{remark}
  Der vorherige besteht aus zwei Teilen. Die Existenz eines
  Häufungspunktes wird unter einer der allgemeinen Bedingung
  getroffen, dass die Menge $K$ kompakt ist, also eine Abstiegsfolge
  nicht ins unendliche konvergieren kann. Diese Bedingung ist oft
  recht leicht nachzuprüfen. Insbesondere steht die Existenz mehrerer
  Häufungspunkte nicht im Widerspruch zu den Annahmen, so dass das
  Verfahren auch dann wenigstens einen davon findet.

  Die weiteren Bedingungen, die sicherstellen, dass es sich bei einem
  Häufungspunkt um einen stationären Punkt handelt, sind lokal in
  einer Umgebung eines solchen gestellt. An diesem Punkt sind die
  Folgen $\gamma_k$ und $\alpha_k$ nur sehr abstrakt fixiert. Wir
  zeigen nun, dass die Folge der $\alpha_k$ im Verfahren des steilsten
  Abstiegs die Bedingung erfüllt. Als zweite Anwendung von allgemeinen
  Abstiegsverfahren stellen wir dann das Newton-Verfahren mit
  Schrittweitensteuerung vor.
\end{remark}

\begin{Korollar}{abstieg-haeufung}
  Beim Verfahren des steilsten Abstiegs sind die Folgen $\gamma_k$ und
  $\alpha_k$ so gewählt, das \slideref{Satz}{abstieg-haeufung} gilt.
\end{Korollar}

\begin{proof}
  Da die Abstiegsrichtungen immer gleich dem (negativen) Gradienten
  sind, gilt $\gamma_k \equiv 1$. Für die Folge $\alpha_k$ zeigen wir
  nich die Beschränktheit durch $\alpha$. Stattdessen bemerken wir mit
  $\lambda$ aus \slideref{Lemma}{abstieg-reduktion}:
  \begin{align}
    g(x^{(k+1)})
    &= \min_{\alpha>0} g\left(x^{(k+1)}-\alpha s^{(k)}\right)\\
    &\le g(x^{(k)}-\lambda s^{(k)})\\
    &\le g(x^{(k)}) - \frac{\lambda}4 \norm{\nabla g(x^*)}.
  \end{align}
  Auch hier schließen wir, dass die Folge divergiert wenn die Punkte konvergieren.
\end{proof}

\begin{Lemma}{newton-abstieg}
  Sei $f\colon \R^n\to \R^n$ stetig differenzierbar und
  $g(x) = \norm{f(x)}_2^2$.  Dann sind die Suchrichtungen
  \begin{gather}
    s^{(k)} = \frac{d^{(k)}}{\norm{d^{(k)}}_2},
    \qquad d^{(k)} = \bigl(\nabla f(x^{(k)})\bigr)^{-1}f(x^{(k)})
  \end{gather}
  Abstiegsrichtungen für $g(x)$ und es gilt
  \begin{gather}
    s^{(k)} \in S_\gamma\bigl(x^{(k)}\bigr),
    \qquad
    \gamma = \frac{1}{\cond_2(\nabla f(x^{(k)}))}
  \end{gather}
\end{Lemma}

\begin{proof}
  Es gilt (Nachrechnen!)
  \begin{gather}
    \nabla g(x) = 2 f(x)^T\nabla f(x).
  \end{gather}
  Daher ist
  \begin{align}
    \frac{\nabla g(x) s}{\norm{\nabla g(x)}_2}
    &= \frac{f(x)^T \nabla f(x) \bigl(\nabla f(c)\bigr)^{-1} f(x)}
      {\norm{f(x)^T\nabla f(x)}_2\norm{\bigl(\nabla f(c)\bigr)^{-1} f(x)}}_2\\
    &\ge \frac{\norm{f(x)}^2_2}{\norm{f(x)}_2\norm{\nabla f(x)}_2\norm{\bigl(\nabla f(c)\bigr)^{-1}}_2\norm{f(x)}_2}\\
    &= \frac1{\cond_2(\nabla f)}.
  \end{align}
\end{proof}

\begin{remark}
  Man kann nun zum Beispiel auch das Newton-Verfahren mit line search
  ausführen, um globale Konvergenzeigenschaften zu erzielen. Es gilt
  dann zunächst die Existenz von Häufungspunkten. In der Nähe eines
  solchen gilt aber natürlich, dass line search nicht schlechter
  konvergiert, als das normale Newton-Verfahren, woraus dann dort
  wieder die quadratische Konvergenz gefolgert werden kann.

  Wir betrachten stattdessen die folgende, einfachere Variante, die
  mit minimaler Modifikation ein global konvergierendes Verfahren
  ergibt.
\end{remark}

\begin{Definition}{newton-stepsize}
  Das Newton-Verfahren mit \define{Schrittweitensteuerung} berechnet iterativ
  $x^{(k+1)}\in \R^n$ aus $x^{(k)}\in \R^n$ in folgenden Schritten
  \begin{enumerate}
  \item Berechne $d^{(k)} = \bigl(\nabla f(x^{(k)})\bigr)^{-1}f(x^{(k)})$
  \item Berechne die kleinste ganze Zahl $j$, so dass
    \begin{multline}
      \norm*{f(x^{(k)}-2^{-j} d^{(k)})}_2^2
      \le \norm*{f(x^{(k)})}_2^2
      \\- 2^{-j} \frac{1}{4\cond_2(\nabla f(x^{(k)}))}
      \norm*{f^T\bigl(x^{(k)}\nabla f(x^{(k)}\bigr)}_2
    \end{multline}
    \item Setze $x^{(k+1)}=x^{(k)}-2^{-j} d^{(k)}$
  \end{enumerate}
\end{Definition}

\begin{remark}
  Der Algorithmus benötigt viele zusätzliche Berechnungen, wie die von
  $\gamma_k$ oder $\nabla g$. Für die praktische Anwendung lässt er
  sich vereinfachen. Dazu beobachten wir zunächst, dass
  Bedingung~\eqref{eq:newton:7} dazu dient, eine hinreichende
  Kontraktion in der Nähe eines Häufungspunkts sicherzustellen. Die
  Existenz eines solchen kann bereits aus
  \begin{gather}
    g\bigl(x^{k+1}\bigr) < g\bigl(x^{k}\bigr)
  \end{gather}
  gefolgert werden. Umgekehrt wird, wenn die Funktion $f$ die
  Bedingungen des Konvergenzsatzes \slideref{Satz}{newton-konvergenz}
  erfüllt, in der Nähe eines Fixpunktes ohnehin $j=0$ gelten. Wir
  ersetzen daher die komplizierte Bedingung durch die wesentlich
  einfachere: sei $j$ die kleinste nichtnegative ganze Zahl, so dass
  \begin{gather}
    \norm*{f\bigl(x^{k} - 2^{-j} d^{(k)}\bigr)}_2^2 < \norm*{f\bigl(x^{k}\bigr)}_2^2.
  \end{gather}
  Es gibt in der Literatur weitere Heuristiken zur Wahl der
  Schrittweite im Newton-Verfahren, die man unter dem Stichwort \glqq
  Globalisierung\grqq{} findet. Hier wollen wir uns mit dieser
  besonders einfachen und gleichzeitig effektiven Variante begnügen.
\end{remark}

\begin{Algorithmus*}{newton-stepsize}{Newton-Verfahren mit Schrittweitensteuerung}
    \lstinputlisting[firstline=3,lastline=18]{code/newton-stepsize.py}
\end{Algorithmus*}

\begin{remark}
  Dieser Abschnitt gibt Hinweise darauf, wie das Newton-Verfahren
  modifiziert werden kann und trotzdem Konvergenz erhalten wird. Neben
  der Schrittweitensteuerung kommen hier insbesondere approximative
  Berechnungen der Ableitung in Frage. Diese werden dann oft als
  \define{Quasi-Newton-Verfahren} bezeichnet, konvergieren in der
  Regel nur von erster Ordnung, sind aber of viel effizienter als das
  Newton-Verfahren selbst.
\end{remark}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
