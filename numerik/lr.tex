\begin{notation}%{quadratische-matrizen}
  Da wir uns in diesem Abschnitt mit der Lösung quadratischer
  Gleichungssysteme beschäftigen, gelte für alle Matrizen, soweit
  nicht anders vermerkt, dass ihre Dimension $n\times n$ sei.
\end{notation}

\subsection{Dreiecksmatrizen und Frobeniusmatrizen}

\begin{Definition}{dreiecksmatrix}
  Für eine \define{untere Dreiecksmatrix} $L \in \R^{n\times n}$ gilt
  \begin{gather}
    \ell_{ij} = 0,\qquad j>i.
  \end{gather}
  Für eine \define{obere Dreiecksmatrix} $R \in \R^{n\times n}$ gilt
  \begin{gather}
    r_{ij} = 0,\qquad j<i.
  \end{gather}
\end{Definition}

\begin{Satz}{dreieck-gruppe}
  Die Mengen der invertierbaren oberen und unteren Dreiecksmatrizen
  bilden jeweils eine multiplikative Gruppe. Die Determinante einer
  Dreiecksmatrix ist das Produkt ihrer Diagonalelemente.
\end{Satz}

\begin{proof}
  Hausaufgabe
\end{proof}

\begin{Korollar}{dreieck-inverse}
  Eine Dreiecksmatrix ist invertierbar genau dann, wenn alle ihre
  Diagonalelemente von null verschieden sind.
\end{Korollar}

\begin{Algorithmus}{vorwaerts-rueckwaerts}
  Die Lösung der linearen Gleichungssysteme
  \begin{gather}
    Lx = b \qquad Rx = b
  \end{gather}
  mit einer unteren Dreiecksmatrix $L$ und einer oberen Dreiecksmatrix
  $R$ lässt sich sukzessive durch Vorwärts- bzw.\ Rückwärtseinsetzen
  berechnen.
  \begin{minipage}[t]{.45\linewidth}
    \lstinputlisting[basicstyle=\footnotesize]{code/forsub.py}    
  \end{minipage}
  \begin{minipage}[t]{.45\linewidth}
    \lstinputlisting[basicstyle=\footnotesize]{code/backsub.py}    
  \end{minipage}
\end{Algorithmus}

\begin{Definition}{frobenius-matrix}
  Eine Matrix der Gestalt
  \begin{gather}
    G_k=\begin{bmatrix}
      1 & & & & & \\
      &\ddots & & & & \\
      &   & 1& & &\\
      &   & g_{k+1,k}&1 & &\\
      &   & \vdots& &\ddots &\\
      &   & g_{nk}& & &1
    \end{bmatrix}
  \end{gather}
  mit von null verschiedenen Subdiagonaleinträgen nur in Spalte $k$
  heißt \define{Frobenius-Matrix}.
\end{Definition}

\begin{Lemma}{frobenius-matrix}
  Das Ergebnis des Produktes $G_kA$ einer Frobeniusmatrix mit einer
  beliebigen Matrix ergibt sich aus $A$ dadurch, dass auf die $j$-te
  Zeile das $g_{jk}$-fache der $k$-ten Zeile addiert wird.

  Für Frobenius-Matrizen gilt
  \begin{gather}
    G_k^{-1} = 2\identity-G_k.
  \end{gather}
  
  Sei $k_1<\dots<k_m$ eine aufsteigende Folge von Indizes. Dann gilt für Produkte die Darstellung
  \begin{gather}
    G_{k_1}\cdots G_{k_m} = \sum_{i=1}^m G_i - (m-1) \identity.
  \end{gather}
  \begin{gather}
    \text{Insbesondere gilt }\qquad
    G_1\cdots G_{n-1} =
    \begin{bmatrix}
      1\\
      g_{21} & 1 \\
      \vdots & \ddots & \ddots \\
      g_{n1}  & \dots & g_{n,n-1} & 1
    \end{bmatrix}
  \end{gather}
\end{Lemma}

\subsection{Konstruktion der LR-Zerlegung}

\begin{Lemma}{elimination-1}
  Bei der Gauß-Elimination lässt sich die Elimination der
  Subdiagonalelemente der $k$-ten Spalte als Matrix-Produkt
  \begin{gather}
    A^{(k+1)} = L^{-1}_k A^{(k)},
    \qquad b^{(k+1)} = L^{-1}_k b^{(k)},
    \qquad k=1,\dots,n-1
  \end{gather}
  mit $A^{(1)}=A$, $b^{(1)}=b$ und den Frobenius-Matrizen
  \begin{gather}
    L_k =\begin{bmatrix}
      1 & & & & & \\
      &\ddots & & & & \\
      &   & 1& & &\\
      &   & \ell_{k+1,k}&1 & &\\
      &   & \vdots& &\ddots &\\
      &   & \ell_{nk}& & &1
    \end{bmatrix},
    \qquad
    \ell_{ik} = \frac{a_{ik}^{(k)}}{a_{kk}^{(k)}}
  \end{gather}
  schreiben.
\end{Lemma}

\begin{Satz}{elimination-2}
  Nach $n-1$ Schritten der Gauß-Elminiation erhält man das transformierte lineare Gleichungssystem
  \begin{gather}
    R x = y,\qquad R = L^{-1}A, \qquad y=L^{-1}b,
    \qquad L = L_1\cdots L_{n-1},
  \end{gather}
  und die LR-Zerlegung
  \begin{gather}
    A = LR
  \end{gather}
  mit einer oberen Dreiecksmatrix $R$ und einer unteren Dreiecksmatrix
  $L$, deren Diagonale aus Einsen besteht.
\end{Satz}

\begin{Algorithmus*}{lr}{LR-Zerlegung}
  \lstinputlisting{code/lu.py}
\end{Algorithmus*}

\begin{remark}
  Im vorigen Algorithmus wird die LR-Zerlegung (engl. LU
  decomposition) so durchgeführt, dass sie die Matrix $A$
  ersetzt. Dadurch wird kein zusätzlicher Speicher benötigt. Nach
  ausführen der Funktion hat dann $A$ nicht mehr die Bedeutung einer
  Matrix, sondern ist ein quadratisches Zahlenfeld, für dessen
  Einträge $a_{ij}$ gilt
  \begin{gather}
    a_{ij} =
    \begin{cases}
      r_{ij} & i \le j\\
      \ell_{ij} & i>j.
    \end{cases}
  \end{gather}
  Von den Diagonaleinträgen von $L$ wissen wir, dass sie den Wert 1
  haben, deswegen werden sie nicht gespeichert.

  Für dieses spezielle Datenformat gibt es dann auch eine
  spezialisierte Version der Auflösung der gestaffelten
  Gleichungssysteme:
\end{remark}

\begin{Algorithmus*}{for-back}{Vorwärts-Rückwärts-Einsetzen}
  \lstinputlisting{code/forward_backward.py}
\end{Algorithmus*}

\begin{Lemma}{aufwand-LR}
  Der Aufwand der LR-Zerlegung einer $n\times n$-Matrix ist
  \begin{gather}
    \tfrac13 n^3 + \bigo(n^2).
  \end{gather}
\end{Lemma}

\begin{Satz}{existenz-LR}
  Ist die Matrix $A$ invertierbar, dann ist im $k$-ten Schritt der
  Gauß-Elimination wenigstens eins der Elemente $a^{(k)}_{jk}$ mit
  $j\ge k$ von null verschieden. für den Fall, dass
  $a^{(k)}_{kk} = 0$, kann damit die Elimination nach Vertauschen der
  Zeilen $j$ und $k$ fortgesetzt werden.
\end{Satz}

\begin{Definition}{spalten-pivot}
  Führt man im $k$-ten Schritt der Gauß-Elimination eine
  Zeilenvertauschung durch, so dass
  \begin{gather}
    \abs{a^{(k)}_{kk}} = \max_{j\ge k} \abs{a^{(k)}_{jk}},
  \end{gather}
  so spricht man von Gauß-Elimination mit
  \define{Spalten-Pivotierung}. Vertauscht man sogar die verbleibenden
  Zeilen und spalten, so dass
  \begin{gather}
    \abs{a^{(k)}_{kk}} = \max_{i,j\ge k} \abs{a^{(k)}_{ij}},
  \end{gather}
  handelt es sich um \define{vollständige Pivotierung}.
\end{Definition}

\begin{Lemma}{spalten-pivot}
  Führt man die Gauß-Elimination mit Spalten-Pivotierung durch, so gilt
  für die Matrix $L$:
  \begin{gather}
    \abs{\ell_{ij}} \le 1,\qquad1\le i,j\le n.
  \end{gather}
\end{Lemma}

\begin{Lemma}{l-p-vertauschung}
  Sei $\pi$ eine Permutation der Zahlen $1,\dots,n$, so dass die
  Zahlen $1,\dots,k$ unverändert bleiben, und $P_{\pi}$ die Matrix der
  entsprechenden Zeilenvertauschungen. Dann ist
  \begin{gather}
    P_\pi L_k P_\pi^{-1} =
    \begin{bmatrix}
      1 & & & & & \\
      &\ddots & & & & \\
      &   & 1& & &\\
      &   & \ell_{\pi(k+1),k}&1 & &\\
      &   & \vdots& &\ddots &\\
      &   & \ell_{\pi(n)k}& & &1
    \end{bmatrix}
  \end{gather}
  wieder eine Frobenius-Matrix gleicher Struktur wie $L_k$.
\end{Lemma}

\begin{proof}
  Jede Permutation ist das Produkt von Transpositionen. Für solche
  wird die Aussage in der Hausaufgabe gezeigt.
\end{proof}

\begin{Satz}{lr-pivot}
  Nach $n-1$ Schritten der Gauß-Elimination mit Spalten-Pivotierung
  erhält man die Zerlegung
  \begin{gather}
    PA = LR
  \end{gather}
  mit einer Permutationsmatrix $P$ und den Dreiecksmatrizen $L$ und $R$.
\end{Satz}

\begin{proof}
  Siehe \cite[Abschnitt 1.3]{DeuflhardHohmann08}.
\end{proof}

\subsection{Fehleranalyse}

Ohne Beweis geben wir die folgenden Resultate zur
Rundungsfehleranalyse der Lösung linearer Gleichungssysteme mit der
LR-Zerlegung an. Teile der Beweise finden sich in~\cite{Stoer83}.

\begin{Notation}{abs-matrix}
  Zu einer Matrix $A$ sei $\abs{A}$ die Matrix der Absolutbeträge, also
  \begin{gather}
    \abs{A} =
    \begin{pmatrix}
      \abs{a_{11}} & \cdots & \abs{a_{1n}} \\
      \vdots && \vdots\\
      \abs{a_{nn}} & \cdots & \abs{a_{nn}}
    \end{pmatrix}.
  \end{gather}
\end{Notation}

% Stoer:
\begin{Lemma}{rundung-lr-1}
  Die Berechnung der LR-Zerlegung einer Matrix $A$ in
  Fließkommaarithmetik resultiert in einer Zerlegung
  $\widehat L \widehat R = A+\delta A$ und es gilt die Abschätzung
  \begin{gather}
    \abs{\delta A} \le 2\alpha_{\max} \frac{\eps}{1-\eps}
    \begin{pmatrix}
      0&0&0&\cdots&0&0\\
      1&1&1&\cdots&1&1\\
      1&2&2&\cdots&2&2\\
      1&2&3&\cdots&3&3\\
      \vdots&\vdots&\vdots&\cdots&n-1&n-1
    \end{pmatrix}
  \end{gather}
  Hierbei ist $\alpha_{\max}$ der betragsmäßig größte Eintrag
  aller Matrizen $A^{(k)}$, die im Verfahren auftreten,
  \begin{gather}
    \alpha_{\max} = \max_{1\le k,i,j\le n} \abs{a^{(k)}_{ij}}.
  \end{gather}
\end{Lemma}

% Deuflhard:
% \begin{Lemma}{rundung-lr-1}
%   Die Matrix $A$ besitze eine LR-Zerlegung. Dann berechnet das
%   Gaußsche Eliminationsverfahren für das Gleichungssystem $AX=b$ die
%   Lösung $\widehat x$ des Systems $(A+\delta A) \widehat x = b$ für eine Matrix
%   $A+\delta A$ mit
%   \begin{gather}
%     \abs{\delta a_{ij}} \lessdot 2n \abs{\widehat \ell_{ij}}
%     \abs{\widehat r_{ij}}\eps.
%   \end{gather}
% \end{Lemma}

\begin{Lemma}{rundung-vor-rueck}
  Die Realisierung des Vorwärtseinsetzens für das Gleichungssystem
  $Lx = b$ in Fließkommaarithmetik berechnet die Lösung $\widehat x$ des
  gestörten Systems $\widehat L \widehat x = b$ mit
  \begin{gather}
    \abs{L - \widehat L}
    \le \frac{\eps}{1-n\eps} \left(\abs{L}
      \begin{pmatrix}
        1\\&2\\&&\ddots\\&&&n
      \end{pmatrix}
      .-\id \right)
  \end{gather}
\end{Lemma}


\begin{Satz*}{rundung-lr-2}{Wilkinson}
  Das Gaußsche Eliminationsverfahren mit Spaltenpivotierung für das
  Gleichungssystem $Ax=b$ berechnet die Lösung $\widehat x$ des Systems
  $\widehat A \widehat x = b$ für eine Matrix $\widehat A$ mit
  \begin{gather}
    \frac{\norm{\delta A}_\infty}{\norm{A}_\infty}
    \lessdot 2 n^3 \frac{\alpha_{\max}}{\max \abs{a_{ij}}} \eps,
  \end{gather}
  wobei
  \begin{gather}
    \alpha_{\max} = \max_{1\le k,i,j\le n} \abs{a^{(k)}_{ij}}.
  \end{gather}
\end{Satz*}

\begin{remark}
  Im Allgemeinen kann die Konstante $\alpha_{\max}$ durch den Wert
  $2^{n-1} \max a_{ij}$ abgeschätzt werden. Dies führt bei
  größeren Matrizen sehr schnell zu inakzeptablen Fehlern.
  Es gibt aber einige Aussagen über die LR-Zerlegung von Matrizen mit
  spezielleren Strukturen. So gilt
  \begin{enumerate}
  \item Ist die Matrix $A$ invertierbar und schwach diagonaldominant,
    das heißt,
    \begin{gather}
      a_{ii} \ge \sum_{j\neq i} \abs{a_{ij}},
      \qquad i=1,\dots,n,
    \end{gather}
    so kann die LR-Zerlegung ohne Pivotierung durchgeführt werden.
  \item Ist die Matrix $A$ positiv definit, so kann die LR-Zerlegung
    ohne Pivotierung durchgeführrt werden und alle Diagonalelemente
    $a_{kk}^{(k)}$ sind positiv (siehe \cite[Satz 4.7]{Rannacher17}).
  \item Für symmetrisch positiv definite Matrizen führt man die
    Gauß-Elimination in der Variante des
    \putindex{Choleski-Verfahren}s durch, das eine $LL^T$-Zerlegung
    mit dem halben Aufwand der LR-Zerlegung produziert.
  \item Hat die Matrix eine Struktur, bei der sich alle von null
    verschiedenen Einträge um die Diagonale konzentrieren, man spricht
    von Band- und Skyline-Matrizen, so kann man bei der LR-Zerlegung
    diese Struktur ausnutzen und erheblich an Operationen sparen.
  \end{enumerate}
\end{remark}

\begin{remark}
  Hat man über die LR-Zerlegung eine Näherungslösung
  $\widehat x = x+\delta x$ von $Ax=b$ berechnet, so kann das Residuum
  \begin{gather}
    r(\widehat x) = b-A \widehat x
  \end{gather}
  berechnet werden und gibt Aufschluss über den Fehler. Insbesondere gilt
  \begin{gather}
    \delta x = A^{-1} r(\widehat x),
  \end{gather}
  was aber nicht berechenbar ist, da wir die Inverse von $A$ nicht
  exakt kennen. Wir können aber $\delta x$ mit derselben relativen
  Genauigkeit wie $x$ durch den Vektor $\widehat{\delta x}$ approximieren, indem
  wir mit der bereits berechneten LR-Zerlegung
  \begin{gather}
    \widehat L \widehat R \widehat{\delta x} = r(\widehat x)
  \end{gather}
  lösen. Dann ist aber $\widehat x + \widehat{\delta x}$ eine
  Approximation an $x$, deren absoluter Fehler dem von
  $\widehat{\delta x}$ entspricht, ist also genauer als $\widehat x$.
  Offenbar lässt sich dieser Prozess wiederholen
\end{remark}

\begin{Definition}{nachiteration}
  Sei $\widehat L\widehat R$ die fehlerbehaftete LR-Zerlegung der Matrix $A$
  und $x^{(0)} = \widehat R^{-1}\widehat L^{-1} b$. Dann besteht die
  \define{Nachiteration} (engl. \define{iterative refinement}) aus der
  Iterationsvorschrift
  \begin{gather}
    x^{(k+1)} = x^{(k)} + \widehat R^{-1}\widehat L^{-1}
    \bigl(b-Ax^{(k)}\bigr).
  \end{gather}
\end{Definition}

\begin{Aufgabe}{nachiteration-kontraktion}
  Nutzen Sie \slideref{Satz}{rundung-lr-2} und die Konditionierung der
  Lösung eines linearen Gleichungssystems um eine Bedingung an die
  Genauigkeit der Zerlegung zu stellen, unter der Sie die Konvergenz
  der Nachiteration durch den Banachschen Fixpunktsatz beweisen
  können.
\end{Aufgabe}

\begin{remark}
  Die Funktionsbibliothek LAPACK zur linearen Algebra wird heute als
  Standardimplementation für viele der hier diskutierten Algorithmen
  benutzt, zum Beispiel die LR-Zerlegung. Sie enthält viele
  Optimierungen und benutzt auch automatisch Spaltenpivotierung.
\end{remark}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
