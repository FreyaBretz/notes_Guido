\begin{notation}%{quadratische-matrizen}
  Da wir uns in diesem Abschnitt mit der Lösung quadratischer
  Gleichungssysteme beschäftigen, gelte für alle Matrizen, soweit
  nicht anders vermerkt, dass ihre Dimension $n\times n$ sei.
\end{notation}

\subsection{Dreiecksmatrizen und Frobeniusmatrizen}

\begin{Definition}{dreiecksmatrix}
  Für eine \define{untere Dreiecksmatrix} $L \in \R^{n\times n}$ gilt
  \begin{gather}
    \ell_{ij} = 0,\qquad j>i.
  \end{gather}
  Für eine \define{obere Dreiecksmatrix} $R \in \R^{n\times n}$ gilt
  \begin{gather}
    r_{ij} = 0,\qquad j<i.
  \end{gather}
\end{Definition}

\begin{Satz}{dreieck-gruppe}
  Die Mengen der invertierbaren oberen und unteren Dreiecksmatrizen
  bilden jeweils eine multiplikative Gruppe. Die Determinante einer
  Dreiecksmatrix ist das Produkt ihrer Diagonalelemente.
\end{Satz}

\begin{proof}
  Hausaufgabe
\end{proof}

\begin{Korollar}{dreieck-inverse}
  Eine Dreiecksmatrix ist invertierbar genau dann, wenn alle ihre
  Diagonalelemente von null verschieden sind.
\end{Korollar}

\begin{Algorithmus}{vorwaerts-rueckwaerts}
  Die Lösung der linearen Gleichungssysteme
  \begin{gather}
    Lx = b \qquad Rx = b
  \end{gather}
  mit einer unteren Dreiecksmatrix $L$ und einer oberen Dreiecksmatrix
  $R$ lässt sich sukzessive durch Vorwärts- bzw.\ Rückwärtseinsetzen
  berechnen.
  \begin{minipage}[t]{.45\linewidth}
    \lstinputlisting[basicstyle=\footnotesize]{code/forsub.py}    
  \end{minipage}
  \begin{minipage}[t]{.45\linewidth}
    \lstinputlisting[basicstyle=\footnotesize]{code/backsub.py}    
  \end{minipage}
\end{Algorithmus}

\begin{Definition}{frobenius-matrix}
  Eine Matrix der Gestalt
  \begin{gather}
    G_k=\begin{bmatrix}
      1 & & & & & \\
      &\ddots & & & & \\
      &   & 1& & &\\
      &   & g_{k+1,k}&1 & &\\
      &   & \vdots& &\ddots &\\
      &   & g_{nk}& & &1
    \end{bmatrix}
  \end{gather}
  mit von null verschiedenen Subdiagonaleinträgen nur in Spalte $k$
  heißt \define{Frobenius-Matrix}.
\end{Definition}

\begin{Lemma}{frobenius-matrix}
  Das Ergebnis des Produktes $G_kA$ einer Frobeniusmatrix mit einer
  beliebigen Matrix ergibt sich aus $A$ dadurch, dass auf die $j$-te
  Zeile das $g_{jk}$-fache der $k$-ten Zeile addiert wird.

  Für Frobenius-Matrizen gilt
  \begin{gather}
    G_k^{-1} = 2\identity-G_k.
  \end{gather}
  
  Sei $k_1<\dots<k_m$ eine aufsteigende Folge von Indizes. Dann ist
  \begin{gather}
    G_{k_1}\cdots G_{k_m} = \sum_{i=1}^m G_i - (m-1) \identity.
  \end{gather}
  \begin{gather}
    \text{Insbesondere gilt }\qquad
    G_1\dots G_n =
    \begin{bmatrix}
      1\\
      g_{21} & 1 \\
      \vdots & \ddots & \ddots \\
      g_{n1}  & \dots & g_{n,n-1} & 1
    \end{bmatrix}
  \end{gather}
\end{Lemma}

\subsection{Konstruktion der LR-Zerlegung}

\begin{Lemma}{elimination-1}
  Bei der Gauß-Elimination lässt sich die Elimination der
  Subdiagonalelemente der $k$-ten Spalte als Matrix-Produkt
  \begin{gather}
    A^{(k+1)} = L^{-1}_k A^{(k)},
    \qquad b^{(k+1)} = L^{-1}_k b^{(k)},
    \qquad k=1,\dots,n-1
  \end{gather}
  mit $A^{(1)}=A$, $b^{(1)}=b$ und den Frobenius-Matrizen
  \begin{gather}
    L_k =\begin{bmatrix}
      1 & & & & & \\
      &\ddots & & & & \\
      &   & 1& & &\\
      &   & \ell_{k+1,k}&1 & &\\
      &   & \vdots& &\ddots &\\
      &   & \ell_{nk}& & &1
    \end{bmatrix},
    \qquad
    \ell_{ik} = \frac{a_{ik}^{(k)}}{a_{kk}^{(k)}}
  \end{gather}
  schreiben.
\end{Lemma}

\begin{Satz}{elimination-2}
  Nach $n-1$ Schritten der Gauß-Elminiation erhält man das transformierte lineare Gleichungssystem
  \begin{gather}
    R x = y,\qquad R = L^{-1}A, \qquad y=L^{-1}b,
    \qquad L = L_1\cdots L_{n-1},
  \end{gather}
  und die LR-Zerlegung
  \begin{gather}
    A = LR
  \end{gather}
  mit einer oberen Dreiecksmatrix $R$ und einer unteren Dreiecksmatrix
  $L$, deren Diagonale aus Einsen besteht.
\end{Satz}

\begin{Algorithmus*}{lr}{LR-Zerlegung}
  \lstinputlisting{code/lu.py}
\end{Algorithmus*}

\begin{remark}
  Im vorigen Algorithmus wird die LR-Zerlegung (engl. LU
  decomposition) so durchgeführt, dass sie die Matrix $A$
  ersetzt. Dadurch wird kein zusätzlicher Speicher benötigt. Nach
  ausführen der Funktion hat dann $A$ nicht mehr die Bedeutung einer
  Matrix, sondern ist ein quadratisches Zahlenfeld, für dessen
  Einträge $a_{ij}$ gilt
  \begin{gather}
    a_{ij} =
    \begin{cases}
      r_{ij} & i \le j\\
      \ell_{ij} & i>j.
    \end{cases}
  \end{gather}
  Von den Diagonaleinträgen von $L$ wissen wir, dass sie den Wert 1
  haben, deswegen werden sie nicht gespeichert.

  Für dieses spezielle Datenformat gibt es dann auch eine
  spezialisierte Version der Auflösung der gestaffelten
  Gleichungssysteme:
\end{remark}

\begin{Algorithmus*}{for-back}{Vorwärts-Rückwärts-Einsetzen}
  \lstinputlisting{code/forward_backward.py}
\end{Algorithmus*}

\begin{Lemma}{aufwand-LR}
  Der Aufwand der LR-Zerlegung einer $n\times n$-Matrix ist
  \begin{gather}
    \tfrac13 n^3 + \bigo(n^2).
  \end{gather}
\end{Lemma}

\begin{Satz}{existenz-LR}
  Ist die Matrix $A$ invertierbar, dann ist im $k$-ten Schritt der
  Gauß-Elimination wenigstens eins der Elemente $a^{(k)}_{jk}$ mit
  $j\ge k$ von null verschieden. für den Fall, dass
  $a^{(k)}_{kk} = 0$, kann damit die Elimination nach Vertauschen der
  Zeilen $j$ und $k$ fortgesetzt werden.
\end{Satz}

\begin{Definition}{spalten-pivot}
  Führt man im $k$-ten Schritt der Gauß-Elimination eine
  Zeilenvertauschung durch, so dass
  \begin{gather}
    \abs{a^{(k)}_{kk}} = \max_{j\ge k} \abs{a^{(k)}_{jk}},
  \end{gather}
  so spricht man von Gauß-Elimination mit
  \define{Spalten-Pivotierung}. Vertauscht man sogar die verbleibenden
  Zeilen und spalten, so dass
  \begin{gather}
    \abs{a^{(k)}_{kk}} = \max_{i,j\ge k} \abs{a^{(k)}_{ij}},
  \end{gather}
  handelt es sich um \define{vollständige Pivotierung}.
\end{Definition}

\begin{Lemma}{spalten-pivot}
  Führt man die Gauß-Elimination mit Spalten-Pivotierung durch, so gilt
  für die Matrix $L$:
  \begin{gather}
    \abs{\ell_{ij}} \le 1,\qquad1\le i,j\le n.
  \end{gather}
\end{Lemma}

\begin{Lemma}{l-p-vertauschung}
  Sei $\pi$ eine Permutation der Zahlen $1,\dots,n$, so dass die
  Zahlen $1,\dots,k$ unverändert bleiben, und $P_{\pi}$ die Matrix der
  entsprechenden Zeilenvertauschungen. Dann ist
  \begin{gather}
    P_\pi L_k P_\pi^{-1} =
    \begin{bmatrix}
      1 & & & & & \\
      &\ddots & & & & \\
      &   & 1& & &\\
      &   & \ell_{\pi(k+1),k}&1 & &\\
      &   & \vdots& &\ddots &\\
      &   & \ell_{\pi(n)k}& & &1
    \end{bmatrix}
  \end{gather}
  wieder eine Frobenius-Matrix gleicher Struktur wie $L_k$.
\end{Lemma}

\begin{proof}
  Jede Permutation ist das Produkt von Transpositionen. Für solche
  wird die Aussage in der Hausaufgabe gezeigt.
\end{proof}

\begin{Satz}{lr-pivot}
  Nach $n-1$ Schritten der Gauß-Elimination mit Spalten-Pivotierung
  erhält man die Zerlegung
  \begin{gather}
    PA = LR
  \end{gather}
  mit einer Permutationsmatrix $P$ und den Dreiecksmatrizen $L$ und $R$.
\end{Satz}

\begin{proof}
  Siehe \cite[Abschnitt 1.3]{DeuflhardHohmann08}.
\end{proof}

\subsection{Fehleranalyse}

Ohne Beweis geben wir die folgenden Resultate zur
Rundungsfehleranalyse der Lösung linearer
Gleichungssysteme mit der LR-Zerlegung an.

\begin{Lemma}{rundung-vor-rueck}
  Die Realisierung des Vorwärtseinsetzens für das Gleichungssystem
  $LX = b$ in Fließkommaarithmetik berechnet die Lösung $\hat x$ des
  gestörten Systems $\hat L \hat x = b$ mit
  \begin{gather}
    \abs{\ell_{ij} - \hat\ell_{ij}}
    \lessdot n \abs{l_{ij}} \eps.
  \end{gather}
\end{Lemma}

\begin{Lemma}{rundung-lr-1}
  Die Matrix $A$ besitze eine LR-Zerlegung. Dann berechnet das
  Gaußsche Eliminationsverfahren für das Gleichungssystem $AX=b$ die
  Lösung $\hat x$ des Systems $(A+\delta A) \hat x = b$ für eine Matrix
  $A+\delta A$ mit
  \begin{gather}
    \abs{\delta a_{ij}} \lessdot 2n \abs{\hat \ell_{ij}}
    \abs{\hat r_{ij}}\eps.
  \end{gather}
\end{Lemma}

\begin{Satz*}{rundung-lr-2}{Wilkinson}
  Das Gaußsche Eliminationsverfahren mit Spaltenpivotierung für das
  Gleichungssystem $Ax=b$ berechnet die Lösung $\hat x$ des Systems
  $\hat A \hat x = b$ für eine Matrix $\hat A$ mit
  \begin{gather}
    \frac{\norm{\delta A}_\infty}{\norm{A}_\infty}
    \lessdot 2 n^3 \frac{\alpha_{\max}}{\max \abs{a_{ij}}} \eps,
  \end{gather}
  wobei
  \begin{gather}
    \alpha_{\max} = \max_{1\le k,i,j\le n} \abs{a^{(k)}_{ij}}.
  \end{gather}
\end{Satz*}

\subsection{Anmerkungen zur LR-Zerlegung}

\begin{remark}
  Es gibt einige Aussagen über die LR-Zerlegung von Matrizen mit
  spezielleren Strukturen. So gilt
  \begin{enumerate}
  \item Ist die Matrix $A$ invertierbar und schwach diagonaldominant,
    das heißt,
    \begin{gather}
      \abs{a_{ii}} \ge \sum_{j\neq i} \abs{a_{ij}},
      \qquad i=1,\dots,n,
    \end{gather}
    so kann die LR-Zerlegung ohne Pivotierung durchgeführt werden.
  \item Ist die Matrix $A$ positiv definit, so kann die LR-Zerlegung
    ohne Pivotierung durchgeführrt werden und alle Diagonalelemente
    $a_{kk}^{(k)}$ sind positiv (siehe \cite[Satz 4.7]{Rannacher17}).
  \item Für symmetrisch positiv definite Matrizen führt man die
    Gauß-Elimination in der Variante des
    \putindex{Choleski-Verfahren}s durch, das eine $LL^T$-Zerlegung
    mit dem halben Aufwand der LR-Zerlegung produziert.
  \item Hat die Matrix eine Struktur, bei der sich alle von null
    verschiedenen Einträge um die Diagonale konzentrieren, man spricht
    von Band- und Skyline-Matrizen, so kann man bei der LR-Zerlegung
    diese Struktur ausnutzen und erheblich an Operationen sparen.
  \end{enumerate}
\end{remark}

\begin{remark}
  Die Funktionsbibliothek LAPACK zur linearen Algebra wird heute als
  Standardimplementation für viele der hier diskutierten Algorithmen
  benutzt, zum Beispiel die LR-Zerlegung. Sie enthält viele
  Optimierungen und benutzt auch automatisch Spaltenpivotierung.
\end{remark}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
