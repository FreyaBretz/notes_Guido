\subsection{Eigenwerte und die Spektralnorm}

\begin{Definition}{eigenwert}
  Sei $A\in \R^{n\times n}$. Gilt für einen Vektor $0\neq x\in \R^n$
  \begin{gather}
    Ax = \lambda x,
  \end{gather}
  so nennen wir $\lambda$ \define{Eigenwert} von $A$ und $x$ einen
  zugehörigen \define{Eigenvektor}. Wir notieren die Zugehörigkeit zur
  Matrix $A$ auch explizit durch $\lambda(A)$.
\end{Definition}

\begin{Lemma}{ew-norm}
  Für alle Eigenwerte $\lambda\in\C$ einer Matrix $A\in\R^{n\times n}$ gilt
  \begin{gather}
    \abs{\lambda} \le \norm{A}
  \end{gather}
  für jede zu einer beliebigen Vektornorm verträglichen Norm.
\end{Lemma}

\begin{Satz}{onb-ev}
  Sei $A\in \R^n\times n$ eine symmetrische Matrix. Dann gibt es eine
  orthonormalbasis des $\R^n$ von Eigenvektoren $v^{(i)}$ mit zugehörigen
  reellen Eigenwerten $\lambda_i$.
\end{Satz}

\begin{proof}
  Resultat der linearen Algebra.
\end{proof}

\begin{Satz}{spektralnorm}
  Die Operatornorm zur euklidischen Norm\index{Norm!euklidisch} ist
  die \define{Spektralnorm}
  \begin{gather}
    \norm{A}_2 = \max_{\substack{x\in\R^n\\x\neq0}}
    \sqrt{\frac{x^TA^TAx}{x^Tx}} = \sqrt{\lambda_{\max}(A^TA)}.
  \end{gather}
  Insbesondere gilt für symmetrische Matrizen
  $\norm{A}_2 = \max_i\abs{\lambda_i(A)}$.
\end{Satz}

\begin{proof}
  Nach \slideref{Satz}{onb-ev} gibt es eine Basis des $\R^n$ von
  Eigenvektoren $v^{(i)}$ von $A^TA$. Jeder beliebige Vektor $x$
  besitzt damit die Darstellung
  \begin{gather}
    x = \sum_{i=1}^n \alpha_i v^{(i)}.
  \end{gather}
  Es gilt nach der Parsevalschen Gleichung
  $\norm{x}_2 = \norm{\alpha}_2$. Ferner gilt mit den Eigenwerten
  $\lambda_i = \lambda_i(A^TA)$
  \begin{gather}
    \norm{Ax}_2^2 = x^TA^TAx = \sum_{i=1}^n \lambda_i \alpha_i^2.
  \end{gather}
  Daher gilt
  \begin{gather}
    \norm{A}_2^2 = \max_{x\in \R^n} \frac{\norm{Ax}^2}{\norm{x}^2}
    = \max_{\alpha} \frac{\sum \lambda_i\alpha_i^2}{\sum\alpha_i^2}
    \le \lambda_{\max}(A^TA).
  \end{gather}
  Da für symmetrische Matrizen $A=A^T$, so ist
  \begin{gather}
    \lambda_{\max}(A^TA) = \lambda_{\max}(A^2) = \lambda_{\max}^2(A)
  \end{gather}
\end{proof}

\begin{Definition}{pos-def}
  Eine Matrix $A\in\R^{n\times n}$ heißt \define{positiv definit}, wenn
  \begin{gather}
    x^TAx > 0 \qquad\forall 0\neq x\in \R^n.
  \end{gather}
\end{Definition}

\begin{Satz}{spd}
  Eine symmetrische Matrix $A\in\R^{n\times n}$ ist positiv definit genau dann, wenn ihre Eigenwerte alle positiv sind.
\end{Satz}

\subsection{Konditionierung der Lösung}

\begin{Definition}{aufgabe-loesung}
  Die Aufgabe, das lineare Gleichungssystem
  \begin{gather}
    Ax=b
  \end{gather}
  zu lösen wandelt die Eingabedaten $(A,b)$ in das Ausgabedatum $x$
  um. Die zugehörige gestörte Aufgabe ist
  \begin{gather}
    (A+\delta A) (x+\delta x) = b+ \delta b,
  \end{gather}
  wobei $\delta A$ und $\delta b$ eine Matrix und ein Vektor sind, um
  die die Eingabedaten gestört sind. $\delta x$ ist die resultierende
  Störung der Lösung.
  
  Die Untersuchung der Konditionierung dieser Aufgabe besteht in
  der Bestimmung einer relativen \putindex{Konditionszahl} $\kappa$, so dass
  \begin{gather}
    \frac{\norm{\delta x}}{\norm{x}}
    \le \kappa \left[\frac{\norm{\delta A}}{\norm{A}}
      +\frac{\norm{\delta b}}{\norm{b}}\right].
  \end{gather}
\end{Definition}

\begin{Lemma}{gestoert-invertierbar}
  Sei $B\in \R^{n\times n}$ mit $\norm{B} < 1$. Dann ist $I-B$
  invertierbar und es gilt
  \begin{gather}
    \norm{(I-B)^{-1}} \le (1-\norm{B})^{-1}
  \end{gather}
\end{Lemma}

\begin{proof}
  Siehe \cite[Hilfssatz 4.4]{Rannacher17}.
\end{proof}

\begin{Satz}{kondition-lgs}
  Sei die Matrix $A\in\R^{n\times n}$ invertierbar und
  \begin{gather}
    \label{eq:la1:1}
    \norm{\delta A} < \frac1{\norm{A^{-1}}}.
  \end{gather}
  Dann ist die gestörte Matrix $A+\delta A$ ebenfalls invertierbar und
  es gilt die Fehlerabschätzung
  \begin{gather}
    \frac{\norm{\delta x}}{\norm{x}}
    \le \frac{\cond(A)}{1-\cond(A)\nicefrac{\norm{\delta A}}{{\norm{A}}}}
    \left[\frac{\norm{\delta A}}{\norm{A}}
      +\frac{\norm{\delta b}}{\norm{b}}\right].
  \end{gather}
  Hierzu definieren wir die \define{Konditionszahl} der Matrix $A$ zur
  Norm $\norm{\cdot}$
  \begin{gather}
    \cond(A) = \norm{A} \,\norm{A^{-1}}
  \end{gather}
\end{Satz}

\begin{proof}
  Siehe \cite[Satz 4.1]{Rannacher17}.
\end{proof}

\begin{remark}
  \slideref{Satz}{kondition-lgs} gilt unabhängig von der Wahl der
  Norm, sobald die Konditionszahl der Matrix konsistent definiert
  ist. Es ist dabei durchaus möglich, dass die
  Bedingung~\eqref{eq:la1:1} bezüglich einer Norm verletzt, bezüglich
  einer anderen erfüllt ist. Die Invertierbarkeit der gestörten Matrix
  hängt dabei nicht von der Wahl einer Norm ab. Es genügt also, die
  Bedingung bezüglich einer geeigneten Norm zu überprüfen.
\end{remark}

\begin{remark}
  Die Bedingung~\eqref{eq:la1:1} wurde benutzt, um die
  Invertierbarkeit der gestörten Matrix zu sichern. Daraus lässt sich
  ableiten, dass Nichtsingularität einer Matrix $A$ in der Regel nicht
  hinreicht, um auch numerisch ein Gleichungssystem lösen zu
  können. Man benötigt vielmehr, dass eine Matrix nicht nur
  invertierbar ist, sondern dass die Inverse auch hinreichend
  beschränkt werden kann. Insbesondere sehen wir am Nenner der
  Abschätzung, dass bei sehr großer Norm der Inversen schon sehr
  kleine Störungen der Matrix zu einer erheblichen Vergrößerung des
  Fehlers führen.

  Damit tritt neben die rein qualitative Aussage eine Matrix sei
  \putindex{singulär} oder \putindex{invertierbar} die quantitative
  Aussage, dass eine Matrix schlecht invertierbar sei, weil sich
  Datenfehler sehr stark verstärken.

  Zerlegen wir die Konditionszahl in
  \begin{gather}
    \kappa = \frac{\cond(A)}{1-\cond(A)\nicefrac{\norm{\delta A}}{\norm{A}}}
    =\cond(A)\frac{1}{1-\norm{\delta A}{\norm{A^{-1}}}},
  \end{gather}
  so sehen wir, dass auch bei exakter Repräsentation der Matrix die
  Verstärkung von Fehlern der rechten Seite schon durch die
  Konditionszahl bestimmt ist. Da die Konditionszahl nie besser als
  eins ist, gibt es grundsätzlich keine Dämpfung der relativen Fehler.
\end{remark}

\begin{remark}
  Ohne Einschränkung der Allgemeinheit ist das Resultat von
  \slideref{Satz}{kondition-lgs} scharf. Dennoch ist es in der Praxis
  oft zu pessimistisch. Für eine Verbesserung benötigt man jedoch mehr
  Struktureigenschaften der Matrix, zum Beispiel Symmetrie oder die
  Untersuchung invarianter Unterräume.
\end{remark}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
