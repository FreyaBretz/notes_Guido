
\subsection{Simple iterations}

\begin{Algorithm*}{vector-iteration}{Vector iteration (power method)}
  \begin{algorithmic}[1]
    \Require $\mata\in\Cnn$, initial vector $\vv^{(0)}\in\C^n$
    \For{$k=1,\dots$ until convergence}
    \State $\vy \gets \mata \vv^{(k-1)}$
    \State $\alpha_k = \frac{\vy_i}{\vv^{(k-1)}_i}$
    where $\abs{\vv^{(k)}_i}$ is maximal
    \State $\vv^{(k)} = \frac{\vy}{\norm{\vy}}$
    \EndFor
  \end{algorithmic}
\end{Algorithm*}

\begin{Theorem}{vector-iteration}
  Lat $\mata\in\Cnn$ be diagonalizable such that $\lambda_1$ is the
  unique eigenvalue with maximal modulus. Let furthermore the
  component of $v^{(0)}$ in direction of the first eigenvector be
  nonzero. Then, the factors $\alpha_k$ and vectors $v^{(k)}$ of the
  vector iteration converge to the eigenvalue $\lambda_1$ and its
  associated eigenvector. Moreover, there holds
  \begin{align}
    \abs{\alpha_{k+1}-\lambda_1}
    &\le \frac{\abs{\lambda_1}}{\abs{\lambda_2}} \abs{\alpha_{k}-\lambda_1}\\
    \norm{v^{(k+1)}-u_1}
    &\le \frac{\abs{\lambda_1}}{\abs{\lambda_2}} \norm{v^{(k)}-u_1}
  \end{align}
\end{Theorem}

\begin{Remark}{vector-iteration}
  The proof actually requires, that the entry defining $\alpha_k$
  remains the same during the iteration, at least during the steps
  used for detecting convergence.

  The result does not actually require that $\mata$ is diagonalizable,
  as long as $\lambda_1$ is single and of largest modulus.
\end{Remark}

\begin{Lemma}{Rayleigh-approximation}
  Let $(\lambda,\vv)$ be an eigenpair of the Hermitian matrix
  $\mata\in\Cnn$, and let $\vw\i\C^n$. Then, there is a constant $C$ depending only on the matrix $\mata$ such that there holds
  \begin{gather}
    \abs{R_\mata(\vw)-\lambda} \le C \norm{\vw-\vv}^2,
  \end{gather}
  where $R_\mata(\vw)$ is the \putindex{Rayleigh quotient} from
  \slideref{Definition}{rayleigh-quotient}.
\end{Lemma}

\begin{Algorithm*}{shifted-vector-iteration}{Shifted vector iteration}
  The vector iteration can be applied to the matrix $\mata-\sigma\id$
  for some $\sigma\in\C$.

  Then, $\alpha_k$ converges to the eigenvalue $\lambda$ such that
  $\lambda-\sigma$ has largest modulus. $v^{(k)}$ converges to an
  eigenvector for this eigenvalue.
\end{Algorithm*}

\begin{Algorithm*}{inverse-iteration}{The inverse power method}
    \begin{algorithmic}[1]
    \Require $\mata\in\Cnn$, $\sigma\in\C$, initial vector $\vv^{(0)}\in\C^n$
    \For{$k=1,\dots$ until convergence}
    \State Solve $(\mata-\sigma\id) \vy = \vv^{(k-1)}$
    \State $\vv^{(k)} = \frac{\vy}{\norm{\vy}}$
    \State $\alpha_k = R_\mata(\vv^{(k)})$
    \EndFor
  \end{algorithmic}
\end{Algorithm*}

\begin{Algorithm*}{Rayleigh-iteration}{The Rayleigh quotient iteration}
    \begin{algorithmic}[1]
    \Require $\mata\in\Cnn$, $\sigma_0\in\C$, initial vector $\vv^{(0)}\in\C^n$
    \For{$k=1,\dots$ until convergence}
    \State Solve $(\mata-\sigma_{k-1}\id) \vy = \vv^{(k-1)}$
    \State $\vv^{(k)} = \frac{\vy}{\norm{\vy}}$
    \State $\sigma_k = R_\mata(\vv^{(k)})$
    \EndFor
  \end{algorithmic}  
\end{Algorithm*}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
